{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m4 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load HuggingFace dataset into Arize Phoenix running in Docker.\n",
    "\n",
    "!uv pip install arize-phoenix datasets pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dwb2023/ragas-golden-dataset-v2 from HuggingFace...\n",
      "Loaded 12 rows with columns: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name']\n",
      "Prepared dataset with columns: ['question', 'contexts', 'reference_answer', 'model_name', 'id']\n",
      "📤 Uploading dataset...\n",
      "❌ Upload failed: Dataset with the same name already exists: name='ragas_golden_v2'\n",
      "📤 Uploading dataset...\n",
      "❌ Fallback failed: Dataset with the same name already exists: name='ragas_golden_v2'\n"
     ]
    },
    {
     "ename": "DatasetUploadError",
     "evalue": "Dataset with the same name already exists: name='ragas_golden_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:761\u001b[39m, in \u001b[36mClient._process_dataset_upload_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '409 Conflict' for url 'http://localhost:6006/v1/datasets/upload?sync=true'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetUploadError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mload_ragas_to_phoenix\u001b[39m\u001b[34m(dataset_name, phoenix_dataset_name)\u001b[39m\n\u001b[32m     36\u001b[39m client = px.Client(endpoint=\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:6006\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_mapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mphoenix_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# user_input -> question\u001b[39;49;00m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreference_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# reference -> reference_answer\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Dataset uploaded to Phoenix: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:523\u001b[39m, in \u001b[36mClient.upload_dataset\u001b[39m\u001b[34m(self, dataset_name, dataframe, csv_file_path, input_keys, output_keys, metadata_keys, inputs, outputs, metadata, dataset_description)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for type-checker\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_tabular_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_json_dataset(\n\u001b[32m    532\u001b[39m     dataset_name=dataset_name,\n\u001b[32m    533\u001b[39m     inputs=inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    536\u001b[39m     dataset_description=dataset_description,\n\u001b[32m    537\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:700\u001b[39m, in \u001b[36mClient._upload_tabular_dataset\u001b[39m\u001b[34m(self, table, dataset_name, input_keys, output_keys, metadata_keys, dataset_description, action)\u001b[39m\n\u001b[32m    687\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.post(\n\u001b[32m    688\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mv1/datasets/upload\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    689\u001b[39m     files={\u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m: file},\n\u001b[32m   (...)\u001b[39m\u001b[32m    698\u001b[39m     params={\u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[32m    699\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_dataset_upload_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:764\u001b[39m, in \u001b[36mClient._process_dataset_upload_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m msg := response.text:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetUploadError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mDatasetUploadError\u001b[39m: Dataset with the same name already exists: name='ragas_golden_v2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:761\u001b[39m, in \u001b[36mClient._process_dataset_upload_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m761\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '409 Conflict' for url 'http://127.0.0.1:6006/v1/datasets/upload?sync=true'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetUploadError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 110\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m os.environ[\u001b[33m'\u001b[39m\u001b[33mPHOENIX_COLLECTOR_ENDPOINT\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Load the dataset (no need to launch_app since Phoenix is in Docker)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m dataset = \u001b[43mload_ragas_to_phoenix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🎉 Access Phoenix UI at: http://localhost:6006\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mload_ragas_to_phoenix\u001b[39m\u001b[34m(dataset_name, phoenix_dataset_name)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     client = px.Client()\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_mapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mphoenix_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreference_answer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Dataset uploaded (fallback method): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:523\u001b[39m, in \u001b[36mClient.upload_dataset\u001b[39m\u001b[34m(self, dataset_name, dataframe, csv_file_path, input_keys, output_keys, metadata_keys, inputs, outputs, metadata, dataset_description)\u001b[39m\n\u001b[32m    521\u001b[39m     table = dataframe \u001b[38;5;28;01mif\u001b[39;00m dataframe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m csv_file_path\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for type-checker\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_tabular_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_json_dataset(\n\u001b[32m    532\u001b[39m     dataset_name=dataset_name,\n\u001b[32m    533\u001b[39m     inputs=inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    536\u001b[39m     dataset_description=dataset_description,\n\u001b[32m    537\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:700\u001b[39m, in \u001b[36mClient._upload_tabular_dataset\u001b[39m\u001b[34m(self, table, dataset_name, input_keys, output_keys, metadata_keys, dataset_description, action)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📤 Uploading dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    687\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.post(\n\u001b[32m    688\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mv1/datasets/upload\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    689\u001b[39m     files={\u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m: file},\n\u001b[32m   (...)\u001b[39m\u001b[32m    698\u001b[39m     params={\u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[32m    699\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_dataset_upload_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/phoenix/session/client.py:764\u001b[39m, in \u001b[36mClient._process_dataset_upload_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m msg := response.text:\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m DatasetUploadError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    766\u001b[39m data = response.json()[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mDatasetUploadError\u001b[39m: Dataset with the same name already exists: name='ragas_golden_v2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load HuggingFace dataset into Arize Phoenix running in Docker.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import phoenix as px\n",
    "\n",
    "def load_ragas_to_phoenix(\n",
    "    dataset_name: str = \"dwb2023/ragas-golden-dataset-v2\",\n",
    "    phoenix_dataset_name: str = \"ragas_golden_v2\"\n",
    ") -> object:\n",
    "    \"\"\"\n",
    "    Load RAGAS dataset into Phoenix Docker instance.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: HF dataset identifier\n",
    "        phoenix_dataset_name: Name for the dataset in Phoenix\n",
    "        \n",
    "    Returns:\n",
    "        Phoenix dataset object\n",
    "    \"\"\"\n",
    "    # Load from HuggingFace\n",
    "    print(f\"Loading {dataset_name} from HuggingFace...\")\n",
    "    hf_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df = hf_dataset.to_pandas()\n",
    "    print(f\"Loaded {len(df)} rows with columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Map RAGAS columns to Phoenix structure\n",
    "    df_mapped = prepare_ragas_for_phoenix(df)\n",
    "    \n",
    "    # Connect to Docker Phoenix instance\n",
    "    try:\n",
    "        # Phoenix should auto-detect the Docker instance on localhost:6006\n",
    "        client = px.Client(endpoint=\"http://localhost:6006\")\n",
    "        \n",
    "        dataset = client.upload_dataset(\n",
    "            dataframe=df_mapped,\n",
    "            dataset_name=phoenix_dataset_name,\n",
    "            input_keys=[\"question\"],  # user_input -> question\n",
    "            output_keys=[\"reference_answer\"]  # reference -> reference_answer\n",
    "        )\n",
    "        print(f\"✅ Dataset uploaded to Phoenix: {dataset}\")\n",
    "        return dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Upload failed: {e}\")\n",
    "        # Try without explicit endpoint\n",
    "        try:\n",
    "            client = px.Client()\n",
    "            dataset = client.upload_dataset(\n",
    "                dataframe=df_mapped,\n",
    "                dataset_name=phoenix_dataset_name,\n",
    "                input_keys=[\"question\"],\n",
    "                output_keys=[\"reference_answer\"]\n",
    "            )\n",
    "            print(f\"✅ Dataset uploaded (fallback method): {dataset}\")\n",
    "            return dataset\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Fallback failed: {e2}\")\n",
    "            raise\n",
    "\n",
    "def prepare_ragas_for_phoenix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform RAGAS dataset to Phoenix-friendly format.\n",
    "    \n",
    "    RAGAS columns: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name']\n",
    "    Phoenix expects: clear input/output separation\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    column_mapping = {\n",
    "        'user_input': 'question',\n",
    "        'reference': 'reference_answer',\n",
    "        'reference_contexts': 'contexts',\n",
    "        'synthesizer_name': 'model_name'\n",
    "    }\n",
    "    \n",
    "    df_clean = df_clean.rename(columns=column_mapping)\n",
    "    \n",
    "    # Convert lists to strings if needed (Phoenix works better with strings)\n",
    "    if 'contexts' in df_clean.columns:\n",
    "        df_clean['contexts'] = df_clean['contexts'].apply(\n",
    "            lambda x: '\\n'.join(x) if isinstance(x, list) else str(x)\n",
    "        )\n",
    "    \n",
    "    # Add ID column if missing\n",
    "    if 'id' not in df_clean.columns:\n",
    "        df_clean['id'] = range(len(df_clean))\n",
    "    \n",
    "    # Ensure string types for text columns\n",
    "    text_cols = ['question', 'reference_answer', 'contexts']\n",
    "    for col in text_cols:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].astype(str)\n",
    "    \n",
    "    print(f\"Prepared dataset with columns: {list(df_clean.columns)}\")\n",
    "    return df_clean\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Fix environment first\n",
    "    import os\n",
    "    if 'PHOENIX_COLLECTOR_ENDPOINT' in os.environ:\n",
    "        del os.environ['PHOENIX_COLLECTOR_ENDPOINT']\n",
    "    \n",
    "    # Load the dataset (no need to launch_app since Phoenix is in Docker)\n",
    "    dataset = load_ragas_to_phoenix()\n",
    "    \n",
    "    print(f\"🎉 Access Phoenix UI at: http://localhost:6006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
