[
  {
    "page_content": " \n\n\nIntroduction - Training | Microsoft Learn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tSkip to main content\n\t\t\n\n\n\n\nThis browser is no longer supported.\n\n\t\t\t\t\t\tUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\t\t\t\t\t\n\n\n\t\t\t\t\t\t\tDownload Microsoft Edge\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tMore info about Internet Explorer and Microsoft Edge\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in English\n\n\n\n\n\nAdd\n\n\n\n\n\nAdd to plan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tAchievements\n\t\t\t\t\t\n\n\n\n\n\n\n\n\n\nAsk Learn\n\n\n\n\n\nAsk Learn\n\n\n\n\n\n\n\nIntroduction\n\n\n\nCompleted\n\n\n\n\n\n2 minutes\n\n\n\n\nAzure AI Speech provides APIs that you can use to build speech-enabled applications. This includes:\n\nSpeech to text: An API that enables speech recognition in which your application can accept spoken input.\nText to speech: An API that enables speech synthesis in which your application can provide spoken output.\nSpeech Translation: An API that you can use to translate spoken input into multiple languages.\nKeyword Recognition: An API that enables your application to recognize keywords or short phrases.\nIntent Recognition: An API that uses conversational language understanding to determine the semantic meaning of spoken input.\n\nThis module focuses on speech recognition and speech synthesis, which are core capabilities of any speech-enabled application.\nIn this module, you'll learn how to:\n\nProvision an Azure resource for the Azure AI Speech service\nUse the Speech to text API to implement speech recognition\nUse the Text to speech API to implement speech synthesis\nConfigure audio format and voices\nUse Speech Synthesis Markup Language (SSML)\n\nThe units in the module include important conceptual information about Azure AI Speech and how to use its API through one of the supported software development kits (SDKs), after which you'll be able to try Azure AI Speech for yourself in a hands-on exercise. To complete the hands-on exercise, you will need a Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.com/free.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback\n\n\n\t\t\t\t\tWas this page helpful?\n\t\t\t\t\n\n\n\n\n\nYes\n\n\n\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\nen-us\n\n\n\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\n\n\n\nTheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Light \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dark \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n High contrast \n\n\n\n\n\n\n\n\n\n\nPrevious Versions\n \nBlog\n \nContribute\n\nPrivacy\n\nTerms of Use\n\nTrademarks\n\n© Microsoft 2025\n\n\n\n\n",
    "metadata": {
      "source": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/1-introduction",
      "title": "Introduction - Training | Microsoft Learn",
      "description": "Introduction",
      "language": "en-us",
      "loader_type": "webbase",
      "source_url": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/1-introduction",
      "load_timestamp": "2025-06-04T02:40:33.409263",
      "doc_type": "html"
    }
  },
  {
    "page_content": " \n\n\nProvision an Azure resource for speech - Training | Microsoft Learn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tSkip to main content\n\t\t\n\n\n\n\nThis browser is no longer supported.\n\n\t\t\t\t\t\tUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\t\t\t\t\t\n\n\n\t\t\t\t\t\t\tDownload Microsoft Edge\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tMore info about Internet Explorer and Microsoft Edge\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in English\n\n\n\n\n\nAdd\n\n\n\n\n\nAdd to plan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tAchievements\n\t\t\t\t\t\n\n\n\n\n\n\n\n\n\nAsk Learn\n\n\n\n\n\nAsk Learn\n\n\n\n\n\n\n\nProvision an Azure resource for speech\n\n\n\nCompleted\n\n\n\n\n\n2 minutes\n\n\n\n\nBefore you can use Azure AI Speech, you need to create an Azure AI Speech resource in your Azure subscription. You can use either a dedicated Azure AI Speech resource or a multi-service Azure AI Services resource.\nAfter you create your resource, you'll need the following information to use it from a client application through one of the supported SDKs:\n\nThe location in which the resource is deployed (for example, eastus)\nOne of the keys assigned to your resource.\n\nYou can view of these values on the Keys and Endpoint page for your resource in the Azure portal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback\n\n\n\t\t\t\t\tWas this page helpful?\n\t\t\t\t\n\n\n\n\n\nYes\n\n\n\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\nen-us\n\n\n\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\n\n\n\nTheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Light \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dark \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n High contrast \n\n\n\n\n\n\n\n\n\n\nPrevious Versions\n \nBlog\n \nContribute\n\nPrivacy\n\nTerms of Use\n\nTrademarks\n\n© Microsoft 2025\n\n\n\n\n",
    "metadata": {
      "source": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/2-create-speech-service",
      "title": "Provision an Azure resource for speech - Training | Microsoft Learn",
      "description": "Provision an Azure resource for speech",
      "language": "en-us",
      "loader_type": "webbase",
      "source_url": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/2-create-speech-service",
      "load_timestamp": "2025-06-04T02:40:33.697693",
      "doc_type": "html"
    }
  },
  {
    "page_content": " \n\n\nUse the Azure AI Speech to Text API - Training | Microsoft Learn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tSkip to main content\n\t\t\n\n\n\n\nThis browser is no longer supported.\n\n\t\t\t\t\t\tUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\t\t\t\t\t\n\n\n\t\t\t\t\t\t\tDownload Microsoft Edge\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tMore info about Internet Explorer and Microsoft Edge\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in English\n\n\n\n\n\nAdd\n\n\n\n\n\nAdd to plan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tAchievements\n\t\t\t\t\t\n\n\n\n\n\n\n\n\n\nAsk Learn\n\n\n\n\n\nAsk Learn\n\n\n\n\n\n\n\nUse the Azure AI Speech to Text API\n\n\n\nCompleted\n\n\n\n\n\n5 minutes\n\n\n\n\nThe Azure AI Speech service supports speech recognition through the following features:\n\nReal-time transcription: Instant transcription with intermediate results for live audio inputs.\nFast transcription: Fastest synchronous output for situations with predictable latency.\nBatch transcription: Efficient processing for large volumes of prerecorded audio.\nCustom speech: Models with enhanced accuracy for specific domains and conditions.\n\nUsing the Azure AI Speech SDK\nWhile the specific details vary, depending on the SDK being used (Python, C#, and so on); there's a consistent pattern for using the Speech to text API:\n\n\n\n\n\nUse a SpeechConfig object to encapsulate the information required to connect to your Azure AI Speech resource. Specifically, its location and key.\nOptionally, use an AudioConfig to define the input source for the audio to be transcribed. By default, this is the default system microphone, but you can also specify an audio file.\nUse the SpeechConfig and AudioConfig to create a SpeechRecognizer object. This object is a proxy client for the Speech to text API.\nUse the methods of the SpeechRecognizer object to call the underlying API functions. For example, the RecognizeOnceAsync() method uses the Azure AI Speech service to asynchronously transcribe a single spoken utterance.\nProcess the response from the Azure AI Speech service. In the case of the RecognizeOnceAsync() method, the result is a SpeechRecognitionResult object that includes the following properties:\n\nDuration\nOffsetInTicks\nProperties\nReason\nResultId\nText\n\n\n\nIf the operation was successful, the Reason property has the enumerated value RecognizedSpeech, and the Text property contains the transcription. Other possible values for Result include NoMatch (indicating that the audio was successfully parsed but no speech was recognized) or Canceled, indicating that an error occurred (in which case, you can check the Properties collection for the CancellationReason property to determine what went wrong).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback\n\n\n\t\t\t\t\tWas this page helpful?\n\t\t\t\t\n\n\n\n\n\nYes\n\n\n\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\nen-us\n\n\n\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\n\n\n\nTheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Light \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dark \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n High contrast \n\n\n\n\n\n\n\n\n\n\nPrevious Versions\n \nBlog\n \nContribute\n\nPrivacy\n\nTerms of Use\n\nTrademarks\n\n© Microsoft 2025\n\n\n\n\n",
    "metadata": {
      "source": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/3-speech-to-text",
      "title": "Use the Azure AI Speech to Text API - Training | Microsoft Learn",
      "description": "Use the Azure AI Speech to text API",
      "language": "en-us",
      "loader_type": "webbase",
      "source_url": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/3-speech-to-text",
      "load_timestamp": "2025-06-04T02:40:33.871043",
      "doc_type": "html"
    }
  },
  {
    "page_content": " \n\n\nUse the text to speech API - Training | Microsoft Learn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tSkip to main content\n\t\t\n\n\n\n\nThis browser is no longer supported.\n\n\t\t\t\t\t\tUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\t\t\t\t\t\n\n\n\t\t\t\t\t\t\tDownload Microsoft Edge\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tMore info about Internet Explorer and Microsoft Edge\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in English\n\n\n\n\n\nAdd\n\n\n\n\n\nAdd to plan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tAchievements\n\t\t\t\t\t\n\n\n\n\n\n\n\n\n\nAsk Learn\n\n\n\n\n\nAsk Learn\n\n\n\n\n\n\n\nUse the text to speech API\n\n\n\nCompleted\n\n\n\n\n\n4 minutes\n\n\n\n\nSimilarly to its Speech to text APIs, the Azure AI Speech service offers other REST APIs for speech synthesis:\n\nThe Text to speech API, which is the primary way to perform speech synthesis.\nThe Batch synthesis API, which is designed to support batch operations that convert large volumes of text to audio - for example to generate an audio-book from the source text.\n\nYou can learn more about the REST APIs in the Text to speech REST API documentation. In practice, most interactive speech-enabled applications use the Azure AI Speech service through a (programming) language-specific SDK.\nUsing the Azure AI Speech SDK\nAs with speech recognition, in practice most interactive speech-enabled applications are built using the Azure AI Speech SDK.\nThe pattern for implementing speech synthesis is similar to that of speech recognition:\n\n\n\n\n\nUse a SpeechConfig object to encapsulate the information required to connect to your Azure AI Speech resource. Specifically, its location and key.\nOptionally, use an AudioConfig to define the output device for the speech to be synthesized. By default, this is the default system speaker, but you can also specify an audio file, or by explicitly setting this value to a null value, you can process the audio stream object that is returned directly.\nUse the SpeechConfig and AudioConfig to create a SpeechSynthesizer object. This object is a proxy client for the Text to speech API.\nUse the methods of the SpeechSynthesizer object to call the underlying API functions. For example, the SpeakTextAsync() method uses the Azure AI Speech service to convert text to spoken audio.\nProcess the response from the Azure AI Speech service. In the case of the SpeakTextAsync method, the result is a SpeechSynthesisResult object that contains the following properties:\n\nAudioData\nProperties\nReason\nResultId\n\n\n\nWhen speech has been successfully synthesized, the Reason property is set to the SynthesizingAudioCompleted enumeration and the AudioData property contains the audio stream (which, depending on the AudioConfig may have been automatically sent to a speaker or file).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback\n\n\n\t\t\t\t\tWas this page helpful?\n\t\t\t\t\n\n\n\n\n\nYes\n\n\n\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\nen-us\n\n\n\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\n\n\n\nTheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Light \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dark \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n High contrast \n\n\n\n\n\n\n\n\n\n\nPrevious Versions\n \nBlog\n \nContribute\n\nPrivacy\n\nTerms of Use\n\nTrademarks\n\n© Microsoft 2025\n\n\n\n\n",
    "metadata": {
      "source": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/4-text-to-speech",
      "title": "Use the text to speech API - Training | Microsoft Learn",
      "description": "Use the text to speech API",
      "language": "en-us",
      "loader_type": "webbase",
      "source_url": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/4-text-to-speech",
      "load_timestamp": "2025-06-04T02:40:34.022652",
      "doc_type": "html"
    }
  },
  {
    "page_content": " \n\n\nConfigure audio format and voices - Training | Microsoft Learn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\tSkip to main content\n\t\t\n\n\n\n\nThis browser is no longer supported.\n\n\t\t\t\t\t\tUpgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.\n\t\t\t\t\t\n\n\n\t\t\t\t\t\t\tDownload Microsoft Edge\n\t\t\t\t\t\t\n\n\t\t\t\t\t\t\tMore info about Internet Explorer and Microsoft Edge\n\t\t\t\t\t\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead in English\n\n\n\n\n\nAdd\n\n\n\n\n\nAdd to plan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\t\tAchievements\n\t\t\t\t\t\n\n\n\n\n\n\n\n\n\nAsk Learn\n\n\n\n\n\nAsk Learn\n\n\n\n\n\n\n\nConfigure audio format and voices\n\n\n\nCompleted\n\n\n\n\n\n3 minutes\n\n\n\n\nWhen synthesizing speech, you can use a SpeechConfig object to customize the audio that is returned by the Azure AI Speech service.\nAudio format\nThe Azure AI Speech service supports multiple output formats for the audio stream that is generated by speech synthesis. Depending on your specific needs, you can choose a format based on the required:\n\nAudio file type\nSample-rate\nBit-depth\n\nThe supported formats are indicated in the SDK using the SpeechSynthesisOutputFormat enumeration. For example, SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm.\nTo specify the required output format, use the SetSpeechSynthesisOutputFormat method of the SpeechConfig object:\nspeechConfig.SetSpeechSynthesisOutputFormat(SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm);\n\nFor a full list of supported formats and their enumeration values, see the Azure AI Speech SDK documentation.\nVoices\nThe Azure AI Speech service provides multiple voices that you can use to personalize your speech-enabled applications. There are two kinds of voice that you can use:\n\nStandard voices - synthetic voices created from audio samples.\nNeural voices - more natural sounding voices created using deep neural networks.\n\nVoices are identified by names that indicate a locale and a person's name - for example en-GB-George.\nTo specify a voice for speech synthesis in the SpeechConfig, set its SpeechSynthesisVoiceName property to the voice you want to use:\nspeechConfig.SpeechSynthesisVoiceName = \"en-GB-George\";\n\nFor information about voices, see the Azure AI Speech SDK documentation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback\n\n\n\t\t\t\t\tWas this page helpful?\n\t\t\t\t\n\n\n\n\n\nYes\n\n\n\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\nen-us\n\n\n\n\n\n\n\n\nYour Privacy Choices\n\n\n\n\n\n\n\nTheme\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Light \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dark \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n High contrast \n\n\n\n\n\n\n\n\n\n\nPrevious Versions\n \nBlog\n \nContribute\n\nPrivacy\n\nTerms of Use\n\nTrademarks\n\n© Microsoft 2025\n\n\n\n\n",
    "metadata": {
      "source": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/5-audio-format-voices",
      "title": "Configure audio format and voices - Training | Microsoft Learn",
      "description": "Configure audio format and voices",
      "language": "en-us",
      "loader_type": "webbase",
      "source_url": "https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/5-audio-format-voices",
      "load_timestamp": "2025-06-04T02:40:34.174379",
      "doc_type": "html"
    }
  }
]