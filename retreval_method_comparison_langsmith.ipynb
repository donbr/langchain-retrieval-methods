{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Welcome to the **LangChain Retrieval Methods** notebook.  \n",
        "In this tutorial you will:\n",
        "\n",
        "1. **Load** a small corpus of John Wick movie reviews.\n",
        "2. **Explore** seven distinct retrieval strategies:\n",
        "   - Naive (whole‚Äêdocument vectors)\n",
        "   - BM25 (keyword matching)\n",
        "   - Contextual Compression (reranking)\n",
        "   - Multi‚ÄêQuery (query expansion)\n",
        "   - Parent Document (hierarchical chunks)\n",
        "   - Ensemble (fusion of methods)\n",
        "   - Semantic (boundary‚Äêaware chunking)\n",
        "\n",
        "3. **Compare** each method across:\n",
        "   - Retrieval **quality** (recall, qualitative response patterns)\n",
        "   - **Latency** (ms per query)\n",
        "   - **Cost** (API/token usage)\n",
        "   - **Resource footprint** (index size & shape)\n",
        "\n",
        "4. **Visualize** key metrics and response examples to understand trade-offs.\n",
        "\n",
        "By the end of the notebook, you‚Äôll know:\n",
        "- When to **start simple** (Naive or BM25) versus **scale up** (Ensemble or Semantic).\n",
        "- How context-window advances (4 K ‚Üí 32 K ‚Üí 128 K) and loader-splitter decoupling shape modern RAG architectures.\n",
        "- Practical tips for **production readiness**, including index sharding, zero-downtime reindexes, and drift monitoring.\n",
        "\n",
        "> **Prerequisites**  \n",
        "> - Python 3.11 environment (see Quickstart)  \n",
        "> - Access to a Qdrant and Redis instance (using Docker)  \n",
        "> - OpenAI API credentials for embedding & reranking  \n",
        "\n",
        "Run the cells in order, or jump to the section that interests you. Let‚Äôs get started!  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òï üì¥ üî• TLDR ‚òï üì¥ üî•\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| ‚òï Morning Coffee Startup | `docker compose up -d` |\n",
        "| üì¥ That's a Wrap | `docker compose down` |\n",
        "| üî• Burn It All Down | `docker compose down --volumes --rmi all` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Foundation: Docker Containers for Qdrant, Redis, Postgres, and Arize Phoenix (oh my!)\n",
        "\n",
        "- use Docker Compose to setup containers\n",
        "- Draft [Docker Admin Guide](docs/docker-admin-guide.md)\n",
        "- [the `docker-compose.yml file is located here](docker-compose.yml)\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| Start containers | `docker compose up -d` |\n",
        "| Stop containers | `docker compose down` |\n",
        "| Stop containers - remove volumes, images | `docker compose down --volumes --rmi all` |\n",
        "\n",
        "- the last option is great for resets and starting from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Environment Configuration & API Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Build a dynamic project name (e.g. include timestamp)\n",
        "project_name = f\"retrieval-method-comparison-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"COHERE_API_KEY\"] = os.getenv('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = project_name\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv('LANGSMITH_API_KEY')\n",
        "\n",
        "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "QDRANT_API_URL = os.getenv(\"QDRANT_API_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "## üìä Dataset Loading & Preprocessing for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TEMPORARY:  Qdrant and Redis Database reset\n",
        "\n",
        "- For now I'm doing a data reset before each run (ü§∑‚Äç‚ôÇÔ∏è not best practice ü§∑‚Äç‚ôÄÔ∏è)\n",
        "\n",
        "```bash\n",
        "docker compose stop qdrant redis\n",
        "docker compose rm -f qdrant redis\n",
        "docker volume rm langchain-retrieval-methods_qdrant_data langchain-retrieval-methods_redis_data\n",
        "docker compose up -d qdrant redis\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "d794aa3a-234c-4fe7-b219-02e8b36c27ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "john_wick_1.csv already exists.\n",
            "john_wick_2.csv already exists.\n",
            "john_wick_3.csv already exists.\n",
            "john_wick_4.csv already exists.\n"
          ]
        }
      ],
      "source": [
        "# Set up a consistent data directory in the user's home directory\n",
        "from pathlib import Path\n",
        "DATA_DIR = Path.cwd() / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# URLs and filenames\n",
        "urls = [\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\", \"john_wick_1.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\", \"john_wick_2.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\", \"john_wick_3.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\", \"john_wick_4.csv\"),\n",
        "]\n",
        "\n",
        "# Download files if not already present\n",
        "for url, fname in urls:\n",
        "    file_path = DATA_DIR / fname\n",
        "    if not file_path.exists():\n",
        "        print(f\"Downloading {fname}...\")\n",
        "        r = requests.get(url)\n",
        "        r.raise_for_status()\n",
        "        file_path.write_bytes(r.content)\n",
        "    else:\n",
        "        print(f\"{fname} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "all_review_docs = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    loader = CSVLoader(\n",
        "        file_path=(DATA_DIR / f\"john_wick_{i}.csv\"),\n",
        "        metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "    )\n",
        "\n",
        "    movie_docs = loader.load()\n",
        "    for doc in movie_docs:\n",
        "\n",
        "        # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "        doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "        # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "        doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "        # newer movies have a more recent \"last_accessed_at\" (store as ISO string)\n",
        "        doc.metadata[\"last_accessed_at\"] = (datetime.now() - timedelta(days=4-i)).isoformat()\n",
        "\n",
        "    all_review_docs.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## üèóÔ∏è Building RAG Infrastructure: Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AX5XBOIltcvD"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore  # Updated import\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain_community.storage import RedisStore\n",
        "from langchain.storage import create_kv_docstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 1: Simple Vector Storage (Baseline)\n",
        "\n",
        "- creates the vector store using the all_review_docs Document object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6Hta5PoJlos"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/donbr/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/langchain_qdrant/qdrant.py:808: UserWarning: Api key is used with an insecure connection.\n",
            "  client = QdrantClient(**client_options)\n"
          ]
        }
      ],
      "source": [
        "baseline_vectorstore = QdrantVectorStore.from_documents(\n",
        "    all_review_docs,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_baseline\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 2: Hierarchical Storage (Parent-Child Architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Documents: Redis Key-Value Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CjIJlsjsrOSi"
      },
      "outputs": [],
      "source": [
        "redis_byte_store = RedisStore(redis_url=\"redis://localhost:6379\")\n",
        "parent_document_store = create_kv_docstore(redis_byte_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Child Records: Qdrant Vector Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_102727/1364238518.py:2: UserWarning: Api key is used with an insecure connection.\n",
            "  cloud_client = QdrantClient(\n"
          ]
        }
      ],
      "source": [
        "# Initialize Qdrant client\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True\n",
        ")\n",
        "\n",
        "# Check if the Qdrant collection exists\n",
        "if not cloud_client.collection_exists(\"johnwick_parent_children\"):\n",
        "    cloud_client.create_collection(\n",
        "        collection_name=\"johnwick_parent_children\",\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=1536,\n",
        "            distance=models.Distance.COSINE\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Construct the VectorStore using cloud client\n",
        "parent_children_vectorstore = QdrantVectorStore(\n",
        "    embedding=embeddings,\n",
        "    client=cloud_client,\n",
        "    collection_name=\"johnwick_parent_children\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retriever definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_children_vectorstore,\n",
        "    docstore=parent_document_store,\n",
        "    child_splitter=child_splitter,\n",
        ")\n",
        "\n",
        "parent_document_retriever.add_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 3: Vector Storage organized by Semantic Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RmMfpBIcF3dN"
      },
      "outputs": [],
      "source": [
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")\n",
        "\n",
        "semantic_documents = semantic_chunker.split_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_semantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaIgKvJmpjFu"
      },
      "source": [
        "## üéØ Core Learning: 7 Retrieval Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy Setup: Tracing & Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup langsmith tracing\n",
        "\n",
        "from langsmith import Client, traceable\n",
        "\n",
        "langsmith_client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "### Strategy 1: Naive Retrieval (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retriever = baseline_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "### Strategy 2: BM25 Retrieval (Keyword-Based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(all_review_docs)\n",
        "\n",
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "### Strategy 3: Contextual Compression (AI Reranking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "### Strategy 4: Multi-Query Retrieval (Query Expansion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever,\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "### Strategy 5: Parent Document Retrieval (Hierarchical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "### Strategy 6: Ensemble Retrieval (Combined Methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list,\n",
        "    weights=equal_weighting\n",
        ")\n",
        "\n",
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "### Strategy 7: Semantic Retrieval (Semantic Chunking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Performance Monitoring & Evaluation Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Traceable wrappers defined\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable(name=\"naive_retrieval\", run_type=\"chain\", metadata={\"method\":\"naive\"})\n",
        "def trace_naive_retrieval(question: str):\n",
        "    try:\n",
        "        result = naive_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"bm25_retrieval\", run_type=\"chain\", metadata={\"method\":\"bm25\"})\n",
        "def trace_bm25_retrieval(question: str):\n",
        "    try:\n",
        "        # Use the correct chain variable name here\n",
        "        res = bm25_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": res[\"response\"].content,\n",
        "            \"context_docs\": len(res[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"contextual_compression\", run_type=\"chain\", metadata={\"method\":\"compression\"})\n",
        "def trace_contextual_compression(question: str):\n",
        "    try:\n",
        "        result = contextual_compression_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"multi_query_retrieval\", run_type=\"chain\", metadata={\"method\":\"multi_query\"})\n",
        "def trace_multi_query_retrieval(question: str):\n",
        "    try:\n",
        "        result = multi_query_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"parent_document_retrieval\", run_type=\"chain\", metadata={\"method\":\"parent_document\"})\n",
        "def trace_parent_document_retrieval(question: str):\n",
        "    try:\n",
        "        result = parent_document_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"ensemble_retrieval\", run_type=\"chain\", metadata={\"method\":\"ensemble\"})\n",
        "def trace_ensemble_retrieval(question: str):\n",
        "    try:\n",
        "        result = ensemble_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"semantic_retrieval\", run_type=\"chain\", metadata={\"method\":\"semantic\"})\n",
        "def trace_semantic_retrieval(question: str):\n",
        "    try:\n",
        "        result = semantic_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "print(\"‚úÖ Traceable wrappers defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Execution & Real-Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All methods executed with tracing\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "question = \"Did people generally like John Wick?\"\n",
        "\n",
        "naive_retrieval_chain_response = trace_naive_retrieval(question)[\"response\"]\n",
        "bm25_retrieval_chain_response = trace_bm25_retrieval(question)[\"response\"]\n",
        "contextual_compression_retrieval_chain_response = trace_contextual_compression(question)[\"response\"]\n",
        "multi_query_retrieval_chain_response = trace_multi_query_retrieval(question)[\"response\"]\n",
        "semantic_retrieval_chain_response = trace_semantic_retrieval(question)[\"response\"]\n",
        "\n",
        "print(\"‚úÖ All methods executed with tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retrieval traces\n",
        "\n",
        "- broke these two out due to some serialization issues after adopting Redis\n",
        "- helped with troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain_response = trace_parent_document_retrieval(question)[\"response\"]\n",
        "ensemble_retrieval_chain_response = trace_ensemble_retrieval(question)[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tracers.langchain import wait_for_all_tracers\n",
        "\n",
        "# run after all your traceable calls\n",
        "wait_for_all_tracers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results Analysis & Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset: 'retrieval-method-comparison-20250529_142100_runs_ds'\n",
            "üöÄ Added 7 runs to dataset 'retrieval-method-comparison-20250529_142100_runs_ds'\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "# Assume langsmith_client is already initialized,\n",
        "# and `project_name` is set as above.\n",
        "\n",
        "# 1. Ensure the dataset exists or create it\n",
        "dataset_name = f\"{project_name}_runs_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"including method, response, context_docs, tokens, costs, durations, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset: {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset: {dataset.name!r}\")\n",
        "\n",
        "# 2. Fetch all top-level chain runs for the project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "))\n",
        "\n",
        "# 3. Ingest each run as an Example in the dataset\n",
        "for run in runs:\n",
        "    langsmith_client.create_example_from_run(\n",
        "        run=run,\n",
        "        dataset_id=dataset.id\n",
        "    )\n",
        "\n",
        "print(f\"üöÄ Added {len(runs)} runs to dataset {dataset.name!r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View LangGraph Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó View your dataset: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/d3859a9b-6781-4b72-9b94-27739fbb9efb\n"
          ]
        }
      ],
      "source": [
        "print(f\"üîó View your dataset: {dataset.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import timezone, datetime, timedelta\n",
        "\n",
        "# Fetch all top-level chain runs for our project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "    start_time=datetime.now(timezone.utc) - timedelta(hours=1)  # last hour\n",
        "))\n",
        "\n",
        "# Build a record per run, pulling in every field ‚Äúas is‚Äù\n",
        "records = []\n",
        "for run in runs:\n",
        "    records.append({\n",
        "        \"run_id\":          str(run.id),\n",
        "        \"name\":             run.name,\n",
        "        \"method\":           run.metadata.get(\"method\"),\n",
        "        \"status\":           run.status,\n",
        "        \"start_time\":       run.start_time,\n",
        "        \"end_time\":         run.end_time,\n",
        "        \"duration_ms\":      ((run.end_time - run.start_time).total_seconds()*1000)\n",
        "                              if run.start_time and run.end_time else None,\n",
        "        # cost & tokens\n",
        "        \"prompt_tokens\":    run.prompt_tokens,\n",
        "        \"completion_tokens\":run.completion_tokens,\n",
        "        \"total_tokens\":     run.total_tokens,\n",
        "        \"prompt_cost\":      run.prompt_cost,\n",
        "        \"completion_cost\":  run.completion_cost,\n",
        "        \"total_cost\":       run.total_cost,\n",
        "        # errors\n",
        "        \"error\":            run.error,                                   \n",
        "        \"wrapper_error\":    (run.outputs or {}).get(\"error\"),\n",
        "        # wrapper outputs\n",
        "        \"response\":         (run.outputs or {}).get(\"response\"),\n",
        "        \"context_docs\":     (run.outputs or {}).get(\"context_docs\"),\n",
        "    })\n",
        "\n",
        "df_runs = pd.DataFrame.from_records(records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Core Learning: 7 Retrieval Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>name</th>\n",
              "      <th>method</th>\n",
              "      <th>status</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>prompt_cost</th>\n",
              "      <th>completion_cost</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>error</th>\n",
              "      <th>wrapper_error</th>\n",
              "      <th>response</th>\n",
              "      <th>context_docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c7a6e61b-90eb-467e-bc2a-0a03f7676c67</td>\n",
              "      <td>ensemble_retrieval</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:25.485757</td>\n",
              "      <td>2025-05-29 21:23:34.279574</td>\n",
              "      <td>8793.817</td>\n",
              "      <td>6995</td>\n",
              "      <td>177</td>\n",
              "      <td>7172</td>\n",
              "      <td>0.002798</td>\n",
              "      <td>0.0002832</td>\n",
              "      <td>0.0030812</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked the first John Wic...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6812e52d-9f14-4098-893e-63b6b230bbb9</td>\n",
              "      <td>parent_document_retrieval</td>\n",
              "      <td>parent_document</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:22.866991</td>\n",
              "      <td>2025-05-29 21:23:25.485412</td>\n",
              "      <td>2618.421</td>\n",
              "      <td>784</td>\n",
              "      <td>104</td>\n",
              "      <td>888</td>\n",
              "      <td>0.0003136</td>\n",
              "      <td>0.0001664</td>\n",
              "      <td>0.00048</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided reviews, people generall...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ed00d74d-571f-41ef-8f3c-0a7e20dcb98e</td>\n",
              "      <td>semantic_retrieval</td>\n",
              "      <td>semantic</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:19.705658</td>\n",
              "      <td>2025-05-29 21:23:22.860377</td>\n",
              "      <td>3154.719</td>\n",
              "      <td>3195</td>\n",
              "      <td>142</td>\n",
              "      <td>3337</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>0.0002272</td>\n",
              "      <td>0.0015052</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick, especia...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2087dfac-ac2b-4cdd-a4fe-c7afbdc2e9f0</td>\n",
              "      <td>multi_query_retrieval</td>\n",
              "      <td>multi_query</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:11.354325</td>\n",
              "      <td>2025-05-29 21:23:19.704954</td>\n",
              "      <td>8350.629</td>\n",
              "      <td>5827</td>\n",
              "      <td>380</td>\n",
              "      <td>6207</td>\n",
              "      <td>0.0023308</td>\n",
              "      <td>0.000608</td>\n",
              "      <td>0.0029388</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the reviews provided, people generall...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cd0891ff-657a-42ad-8342-be7788c14ede</td>\n",
              "      <td>contextual_compression</td>\n",
              "      <td>compression</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:08.273032</td>\n",
              "      <td>2025-05-29 21:23:11.353782</td>\n",
              "      <td>3080.750</td>\n",
              "      <td>1579</td>\n",
              "      <td>92</td>\n",
              "      <td>1671</td>\n",
              "      <td>0.0006316</td>\n",
              "      <td>0.0001472</td>\n",
              "      <td>0.0007788</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The fir...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>f73c8f24-8a2d-4875-8d0f-3cf457128b08</td>\n",
              "      <td>bm25_retrieval</td>\n",
              "      <td>bm25</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:06.669245</td>\n",
              "      <td>2025-05-29 21:23:08.272582</td>\n",
              "      <td>1603.337</td>\n",
              "      <td>1292</td>\n",
              "      <td>194</td>\n",
              "      <td>1486</td>\n",
              "      <td>0.0005168</td>\n",
              "      <td>0.0003104</td>\n",
              "      <td>0.0008272</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>People's opinions about John Wick movies vary ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>71ea77f8-aea0-40c7-b59d-dcdd2fd9b614</td>\n",
              "      <td>naive_retrieval</td>\n",
              "      <td>naive</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-29 21:23:04.529172</td>\n",
              "      <td>2025-05-29 21:23:06.667873</td>\n",
              "      <td>2138.701</td>\n",
              "      <td>3823</td>\n",
              "      <td>95</td>\n",
              "      <td>3918</td>\n",
              "      <td>0.0015292</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.0016812</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The rev...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 run_id                       name  \\\n",
              "0  c7a6e61b-90eb-467e-bc2a-0a03f7676c67         ensemble_retrieval   \n",
              "1  6812e52d-9f14-4098-893e-63b6b230bbb9  parent_document_retrieval   \n",
              "2  ed00d74d-571f-41ef-8f3c-0a7e20dcb98e         semantic_retrieval   \n",
              "3  2087dfac-ac2b-4cdd-a4fe-c7afbdc2e9f0      multi_query_retrieval   \n",
              "4  cd0891ff-657a-42ad-8342-be7788c14ede     contextual_compression   \n",
              "5  f73c8f24-8a2d-4875-8d0f-3cf457128b08             bm25_retrieval   \n",
              "6  71ea77f8-aea0-40c7-b59d-dcdd2fd9b614            naive_retrieval   \n",
              "\n",
              "            method   status                 start_time  \\\n",
              "0         ensemble  success 2025-05-29 21:23:25.485757   \n",
              "1  parent_document  success 2025-05-29 21:23:22.866991   \n",
              "2         semantic  success 2025-05-29 21:23:19.705658   \n",
              "3      multi_query  success 2025-05-29 21:23:11.354325   \n",
              "4      compression  success 2025-05-29 21:23:08.273032   \n",
              "5             bm25  success 2025-05-29 21:23:06.669245   \n",
              "6            naive  success 2025-05-29 21:23:04.529172   \n",
              "\n",
              "                    end_time  duration_ms  prompt_tokens  completion_tokens  \\\n",
              "0 2025-05-29 21:23:34.279574     8793.817           6995                177   \n",
              "1 2025-05-29 21:23:25.485412     2618.421            784                104   \n",
              "2 2025-05-29 21:23:22.860377     3154.719           3195                142   \n",
              "3 2025-05-29 21:23:19.704954     8350.629           5827                380   \n",
              "4 2025-05-29 21:23:11.353782     3080.750           1579                 92   \n",
              "5 2025-05-29 21:23:08.272582     1603.337           1292                194   \n",
              "6 2025-05-29 21:23:06.667873     2138.701           3823                 95   \n",
              "\n",
              "   total_tokens prompt_cost completion_cost total_cost error wrapper_error  \\\n",
              "0          7172    0.002798       0.0002832  0.0030812  None          None   \n",
              "1           888   0.0003136       0.0001664    0.00048  None          None   \n",
              "2          3337    0.001278       0.0002272  0.0015052  None          None   \n",
              "3          6207   0.0023308        0.000608  0.0029388  None          None   \n",
              "4          1671   0.0006316       0.0001472  0.0007788  None          None   \n",
              "5          1486   0.0005168       0.0003104  0.0008272  None          None   \n",
              "6          3918   0.0015292        0.000152  0.0016812  None          None   \n",
              "\n",
              "                                            response  context_docs  \n",
              "0  Yes, people generally liked the first John Wic...            21  \n",
              "1  Based on the provided reviews, people generall...             3  \n",
              "2  Yes, people generally liked John Wick, especia...            10  \n",
              "3  Based on the reviews provided, people generall...            16  \n",
              "4  Yes, people generally liked John Wick. The fir...             3  \n",
              "5  People's opinions about John Wick movies vary ...             4  \n",
              "6  Yes, people generally liked John Wick. The rev...            10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df_runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Retrieval Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset 'retrieval-method-comparison-20250529_142100_runs_custom_ds'\n",
            "‚úÖ Added 7 runs to dataset 'retrieval-method-comparison-20250529_142100_runs_custom_ds'\n",
            "üîó Dataset URL: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/0dda7929-ecbd-4e0d-8425-4c540e8f1059\n"
          ]
        }
      ],
      "source": [
        "# 1) Create or load the dataset\n",
        "dataset_name = f\"{project_name}_runs_custom_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"capturing inputs, outputs, tokens, costs, duration, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset {dataset.name!r}\")\n",
        "\n",
        "# 2) Bulk‚Äêingest each run as an Example\n",
        "for _, row in df_runs.iterrows():\n",
        "    langsmith_client.create_example(\n",
        "        dataset_id=dataset.id,\n",
        "        inputs={\n",
        "            \"run_id\": row[\"run_id\"],\n",
        "            \"method\": row[\"method\"],\n",
        "        },\n",
        "        outputs={\n",
        "            # include whichever outputs you care about:\n",
        "            \"response\": row[\"response\"],\n",
        "            \"context_docs\": int(row[\"context_docs\"]),\n",
        "        },\n",
        "        metadata={\n",
        "            # include metrics & error info as metadata\n",
        "            \"status\": row[\"status\"],\n",
        "            \"duration_ms\": float(row[\"duration_ms\"]),\n",
        "            \"prompt_tokens\": int(row[\"prompt_tokens\"]),\n",
        "            \"completion_tokens\": int(row[\"completion_tokens\"]),\n",
        "            \"total_tokens\": int(row[\"total_tokens\"]),\n",
        "            \"prompt_cost\": float(row[\"prompt_cost\"]),\n",
        "            \"completion_cost\": float(row[\"completion_cost\"]),\n",
        "            \"total_cost\": float(row[\"total_cost\"]),\n",
        "            # optionally include error\n",
        "            **({\"error\": row[\"error\"]} if pd.notna(row.get(\"error\")) else {}),\n",
        "            **({\"wrapper_error\": row[\"wrapper_error\"]} if pd.notna(row.get(\"wrapper_error\")) else {}),\n",
        "        }\n",
        "    )\n",
        "print(f\"‚úÖ Added {len(df_runs)} runs to dataset {dataset.name!r}\")\n",
        "print(\"üîó Dataset URL:\", dataset.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYuh2V1vHY6N"
      },
      "source": [
        "## üõ†Ô∏è Exploration Tools & Cleanup Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List of Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYbdWnVHct-",
        "outputId": "11cc0bc2-434d-4512-99ed-870b64c09357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['johnwick_parent_children', 'johnwick_semantic', 'johnwick_baseline']\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant collections\n",
        "\n",
        "existing = [c.name for c in cloud_client.get_collections().collections]\n",
        "\n",
        "print(type(existing))\n",
        "print(existing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qdrant info by Storage Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaFQTs_MzlG",
        "outputId": "7fb85947-3663-4a83-a89f-b06fcf89d772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== baseline ===\n",
            "Exists?       True\n",
            "Point count:  count=100\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== parent ===\n",
            "Exists?       True\n",
            "Point count:  count=4817\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== semantic ===\n",
            "Exists?       True\n",
            "Point count:  count=179\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant vector store collection metadata\n",
        "\n",
        "stores = {\n",
        "    \"baseline\": baseline_vectorstore,\n",
        "    \"parent\":  parent_children_vectorstore,\n",
        "    \"semantic\": semantic_vectorstore,\n",
        "}\n",
        "\n",
        "for name, vs in stores.items():\n",
        "    client = vs.client\n",
        "    col    = vs.collection_name\n",
        "    print(f\"=== {name} ===\")\n",
        "    # 1) Existence check\n",
        "    print(\"Exists?      \", client.collection_exists(col))\n",
        "    # 2) Point count\n",
        "    print(\"Point count: \", client.count(collection_name=col))\n",
        "    # 3) Full collection info\n",
        "    desc   = client.get_collection(collection_name=col)\n",
        "    params = desc.config.params\n",
        "\n",
        "    # ‚Äî Vector dims & metric\n",
        "    vec_field = params.vectors\n",
        "    if isinstance(vec_field, dict):\n",
        "        # multi-vector mode: pick the first VectorParams\n",
        "        vp = next(iter(vec_field.values()))\n",
        "    else:\n",
        "        # single-vector mode: vectors is itself a VectorParams\n",
        "        vp = vec_field\n",
        "    print(\"Dim / metric:\", vp.size, \"/\", vp.distance)\n",
        "\n",
        "    # ‚Äî Shard count & replication factor live on params\n",
        "    print(\"Shards / repl:\", params.shard_number, \"/\", params.replication_factor)\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Redis info for Parent Document Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDXX48ENcaEY",
        "outputId": "3d78a55f-2fc1-49c8-aee1-ffc3ffbf91a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in store: 100\n",
            "Metadata fields present: ['Author', 'Movie_Title', 'Rating', 'Review_Date', 'Review_Title', 'Review_Url', 'last_accessed_at', 'row', 'source']\n",
            "Metadata field types:\n",
            " ‚Ä¢ last_accessed_at: types=['str'], sample='2025-05-26T14:21:07.737461'\n",
            " ‚Ä¢ Movie_Title: types=['str'], sample='John Wick 1'\n",
            " ‚Ä¢ Review_Date: types=['str'], sample='23 March 2023'\n",
            " ‚Ä¢ Review_Url: types=['str'], sample='/review/rw8945545/?ref_=tt_urv'\n",
            " ‚Ä¢ Review_Title: types=['str'], sample=' Violent and gripping story with plenty of unstopped action , shootouts and breathtaking fights\\n'\n",
            " ‚Ä¢ source: types=['str'], sample='/home/donbr/aim/langchain-retrieval-methods/data/john_wick_1.csv'\n",
            " ‚Ä¢ row: types=['int'], sample=5\n",
            " ‚Ä¢ Author: types=['str'], sample='ma-cortes'\n",
            " ‚Ä¢ Rating: types=['int'], sample=7\n",
            "Doc 1 (ID=5b2c2231-42c9-49b3-b81d-f201ed19f504): 1576 characters\n",
            "Doc 2 (ID=bb379887-1494-4d58-bdf1-76fb4d357cee): 562 characters\n",
            "Doc 3 (ID=9d106938-d7aa-42f2-b5f6-e0bb81d84e12): 940 characters\n",
            "Doc 4 (ID=5de11192-9b88-457a-a7de-29e120fd1c66): 222 characters\n",
            "Doc 5 (ID=c2d015b1-8532-4c31-889a-9ca39bd89760): 983 characters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assume `parent_document_store` already has docs via ParentDocumentRetriever\n",
        "#  (i.e. you already did retriever.add_documents(...) or similar)\n",
        "\n",
        "# 1) List all stored keys (document IDs)\n",
        "all_keys = list(parent_document_store.yield_keys())\n",
        "print(f\"Total documents in store: {len(all_keys)}\")\n",
        "# print(\"Document IDs:\", all_keys)\n",
        "\n",
        "# 2) Fetch all Document objects\n",
        "docs = parent_document_store.mget(all_keys)\n",
        "\n",
        "# 3) Examine metadata schema\n",
        "#    Collect all metadata field names across docs\n",
        "all_fields = set()\n",
        "for doc in docs:\n",
        "    all_fields.update(doc.metadata.keys())\n",
        "\n",
        "print(f\"Metadata fields present: {sorted(all_fields)}\")\n",
        "\n",
        "# 4) Show per-field value types and a sample value\n",
        "field_types = {field: set() for field in all_fields}\n",
        "for doc in docs:\n",
        "    for field, val in doc.metadata.items():\n",
        "        field_types[field].add(type(val).__name__)\n",
        "\n",
        "print(\"Metadata field types:\")\n",
        "for field, types in field_types.items():\n",
        "    sample = next((d.metadata[field] for d in docs if field in d.metadata), None)\n",
        "    print(f\" ‚Ä¢ {field}: types={sorted(types)}, sample={sample!r}\")\n",
        "\n",
        "# 5) (Optional) Print out first N docs‚Äô text lengths to gauge ‚Äúdimensions‚Äù\n",
        "for i, doc in enumerate(docs[:5], 1):\n",
        "    text_len = len(doc.page_content)\n",
        "    print(f\"Doc {i} (ID={all_keys[i-1]}): {text_len} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCKwiiOuHi9p"
      },
      "source": [
        "### Delete Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Pe_COpbsHcB7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_102727/3294298368.py:5: UserWarning: Api key is used with an insecure connection.\n",
            "  cloud_client = QdrantClient(\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# initialize client (cloud or on-prem)\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        ")\n",
        "\n",
        "# create conditional deletion flag\n",
        "delete_collection = False\n",
        "\n",
        "if delete_collection:\n",
        "    # list of collections to drop\n",
        "    collections_to_reset = [\n",
        "        \"johnwick_baseline\",\n",
        "        \"johnwick_parent_children\",\n",
        "        \"johnwick_semantic\",\n",
        "    ]\n",
        "\n",
        "    for col_name in collections_to_reset:\n",
        "        # guard against missing collections\n",
        "        if cloud_client.collection_exists(col_name):\n",
        "            cloud_client.delete_collection(\n",
        "                collection_name=col_name,\n",
        "                timeout=60,  # seconds\n",
        "            )\n",
        "            print(f\"Deleted collection: {col_name}\")\n",
        "        else:\n",
        "            print(f\"Collection not found (skipped): {col_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KWMPESVcFT_"
      },
      "source": [
        "### Response Object validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHCFk-PajS6t",
        "outputId": "e77ca077-2d16-41d5-d5dc-fb5036f20e65"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The reviews highlight that the film was praised for its stylish and well-choreographed action sequences, Keanu Reeves' confident and cool performance, and its brisk pacing. Many reviewers called it one of the best action films of the year or even the decade, appreciating its simple yet effective revenge plot and the unique criminal underworld it portrayed. While a few reviews were less enthusiastic, the overall reception was very positive, especially among action fans.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "People's opinions about John Wick movies vary based on the reviews provided.\n",
            "\n",
            "- The first John Wick film (2014) received very positive feedback, described as \"something special\" with smooth, stylish action sequences and a compelling criminal underworld. Reviewers praised Keanu Reeves' performance and the film's kinetic, concise action, recommending it highly, especially for action fans.\n",
            "\n",
            "- However, later installments received more mixed or negative reviews. For example, \"John Wick: Chapter 4\" was called the weakest in the series by one reviewer, criticized for lacking plot and meaning despite long action sequences. \"John Wick 3\" was described by a reviewer as boring, plotless, excessively violent, and filled with stereotypes.\n",
            "\n",
            "Overall, while the original John Wick film was generally liked and appreciated for its style and action, some later films in the series garnered more divided or negative reactions. So, people generally liked the first film but had more mixed feelings about the sequels.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The first film received high praise for its slick action sequences, Keanu Reeves' confident performance, and unique style. Reviews describe it as one of the best action films in recent years, highly entertaining, and a must-see for action fans. However, some later installments like John Wick 3 received more mixed reviews, with comments that \"the magic is gone,\" but the initial reception of John Wick was very positive overall.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the reviews provided, people generally liked the John Wick series, especially the earlier films.\n",
            "\n",
            "- The first John Wick movie is often praised as a \"remarkable, surprising film,\" \"slick, violent fun,\" and one of the best action films in recent years. Reviewers highlight Keanu Reeves' performance, the stylish choreography, and the straightforward yet gripping revenge story. Ratings for the first movie range mostly from 7 to 10 out of 10 in these reviews.\n",
            "\n",
            "- The series as a whole, including John Wick 2 and John Wick 4, has maintained a strong fan base and critical acclaim. One review mentions that the first three films all share the same IMDb rating of 7.4/10 and that \"John Wick: Chapter 4\" might be the best in the series, with a rating of 9/10.\n",
            "\n",
            "- There are some dissenting opinions, especially for the later films (e.g., John Wick 3 and 4), where some reviewers found the action too over-the-top, the plot nonsensical, or the fights repetitive and boring. For example, one review gave John Wick 4 a 1/10, calling it \"Horrible,\" but this seems to be an outlier relative to the other positive reviews.\n",
            "\n",
            "Overall, the consensus from the provided context is that John Wick movies are generally well-liked, especially among action fans, praised for their stylistic action sequences, and Keanu Reeves' portrayal. While not everyone loves every installment, the series is regarded as a successful and entertaining action franchise.\n",
            "\n",
            "**In summary:** Yes, people generally liked John Wick, particularly the earlier movies, and the franchise has maintained a strong positive reception overall.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided reviews, people generally liked John Wick. One review praises the first movie for its well-choreographed action and emotional setup, recommending it highly. Another review states that the John Wick series has been consistently well received and even considers \"John Wick: Chapter 4\" as the best in the series. However, there is also a negative review of \"John Wick 4\" that criticizes the plot and fight scenes. Overall, the majority of reviews suggest that people generally enjoyed the John Wick movies.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked the first John Wick film. Reviews highlight the movie's stylish, well-choreographed action sequences, Keanu Reeves' compelling performance, and its unique and fun take on the revenge thriller genre. Several reviewers describe it as a must-see for action fans, praising its smooth action, emotional undercurrent, and fresh approach compared to typical action films. While some critics found certain aspects simple or formulaic, the overall reception was very positive, especially for the original 2014 film. However, opinions on later sequels are more mixed, with some viewers feeling the franchise lost momentum in the third and fourth installments. But overall, the original John Wick was highly appreciated.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick, especially the first film. Reviews highlight it as a stylish, well-choreographed, and exciting action movie with smooth, intense action sequences and a simple yet effective plot. Many reviewers praised Keanu Reeves' performance and the film's unique take on the action genre, describing it as one of the best action films in recent years. \n",
            "\n",
            "However, opinions on the later films, such as John Wick 3, appear more mixed, with some reviews noting a loss of the original's magic or issues with pacing and narrative. Despite that, the franchise overall is well-received, with John Wick 4 regarded as a strong continuation that maintains the high standards of the series.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to response objects\n",
        "responses = {\n",
        "    \"Naive Retrieval Chain Response\":              naive_retrieval_chain_response,\n",
        "    \"BM25 Retrieval Chain Response\":               bm25_retrieval_chain_response,\n",
        "    \"Contextual Compression Chain Response\":       contextual_compression_retrieval_chain_response,\n",
        "    \"Multi-Query Retrieval Chain Response\":        multi_query_retrieval_chain_response,\n",
        "    \"Parent Document Retrieval Chain Response\":    parent_document_retrieval_chain_response,\n",
        "    \"Ensemble Retrieval Chain Response\":           ensemble_retrieval_chain_response,\n",
        "    \"Semantic Retrieval Chain Response\":           semantic_retrieval_chain_response,\n",
        "}\n",
        "\n",
        "for header, resp in responses.items():\n",
        "    display(Markdown(f\"## {header}\\n\"))\n",
        "    print(\"\\n\")\n",
        "    print(resp)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGRzkNHjPUd"
      },
      "source": [
        "### Retrieval Chain validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vZOd4DL9NS3k",
        "outputId": "860d77fb-83d0-4ec7-a8d3-27cb66d8ae60"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f8317810410>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f82ef9e1150>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10})),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser()),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8314497190>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7f83740e9990>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f8314496990>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f8317810410>), VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10}), ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8314497190>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7f83740e9990>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f8314496990>), ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f82ef9e1150>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10})), MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f8317afb6d0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser())], weights=[0.2, 0.2, 0.2, 0.2, 0.2]),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f82fc2341d0>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f8352172190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f8351ccf590>, root_client=<openai.OpenAI object at 0x7f836c365950>, root_async_client=<openai.AsyncOpenAI object at 0x7f83523c8c90>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to chains\n",
        "chains = {\n",
        "    \"Naive Retrieval\":              naive_retrieval_chain,\n",
        "    \"BM25 Retrieval\":               bm25_retrieval_chain,\n",
        "    \"Contextual Compression\":       contextual_compression_retrieval_chain,\n",
        "    \"Multi-Query Retrieval\":        multi_query_retrieval_chain,\n",
        "    \"Parent Document Retrieval\":    parent_document_retrieval_chain,\n",
        "    \"Ensemble Retrieval\":           ensemble_retrieval_chain,\n",
        "    \"Semantic Retrieval\":           semantic_retrieval_chain,\n",
        "}\n",
        "\n",
        "for title, chain in chains.items():\n",
        "    display(Markdown(f\"## {title}\\n\"))\n",
        "    print(chain)\n",
        "    # print(chain.get_graph().draw_ascii())\n",
        "    print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
