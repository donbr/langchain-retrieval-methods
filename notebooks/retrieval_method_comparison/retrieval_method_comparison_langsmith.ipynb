{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Welcome to the **LangChain Retrieval Methods** notebook.  \n",
        "In this tutorial you will:\n",
        "\n",
        "1. **Load** a small corpus of John Wick movie reviews.\n",
        "2. **Explore** seven distinct retrieval strategies:\n",
        "   - Naive (whole‚Äêdocument vectors)\n",
        "   - BM25 (keyword matching)\n",
        "   - Contextual Compression (reranking)\n",
        "   - Multi‚ÄêQuery (query expansion)\n",
        "   - Parent Document (hierarchical chunks)\n",
        "   - Ensemble (fusion of methods)\n",
        "   - Semantic (boundary‚Äêaware chunking)\n",
        "\n",
        "3. **Compare** each method across:\n",
        "   - Retrieval **quality** (recall, qualitative response patterns)\n",
        "   - **Latency** (ms per query)\n",
        "   - **Cost** (API/token usage)\n",
        "   - **Resource footprint** (index size & shape)\n",
        "\n",
        "4. **Visualize** key metrics and response examples to understand trade-offs.\n",
        "\n",
        "By the end of the notebook, you‚Äôll know:\n",
        "- When to **start simple** (Naive or BM25) versus **scale up** (Ensemble or Semantic).\n",
        "- How context-window advances (4 K ‚Üí 32 K ‚Üí 128 K) and loader-splitter decoupling shape modern RAG architectures.\n",
        "- Practical tips for **production readiness**, including index sharding, zero-downtime reindexes, and drift monitoring.\n",
        "\n",
        "> **Prerequisites**  \n",
        "> - Python 3.11 environment (see Quickstart)  \n",
        "> - Access to a Qdrant and Redis instance (using Docker)  \n",
        "> - OpenAI API credentials for embedding & reranking  \n",
        "\n",
        "Run the cells in order, or jump to the section that interests you. Let‚Äôs get started!  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òï üì¥ üî• TLDR ‚òï üì¥ üî•\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| ‚òï Morning Coffee Startup | `docker compose up -d` |\n",
        "| üì¥ That's a Wrap | `docker compose down` |\n",
        "| üî• Burn It All Down | `docker compose down --volumes --rmi all` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Foundation: Docker Containers for Qdrant, Redis, Postgres, and Arize Phoenix (oh my!)\n",
        "\n",
        "- use Docker Compose to setup containers\n",
        "- Draft [Docker Admin Guide](docs/docker-admin-guide.md)\n",
        "- [the `docker-compose.yml file is located here](docker-compose.yml)\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| Start containers | `docker compose up -d` |\n",
        "| Stop containers | `docker compose down` |\n",
        "| Stop containers - remove volumes, images | `docker compose down --volumes --rmi all` |\n",
        "\n",
        "- the last option is great for resets and starting from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Environment Configuration & API Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Build a dynamic project name (e.g. include timestamp)\n",
        "project_name = f\"retrieval-method-comparison-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"COHERE_API_KEY\"] = os.getenv('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = project_name\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv('LANGSMITH_API_KEY')\n",
        "\n",
        "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "QDRANT_API_URL = os.getenv(\"QDRANT_API_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "## üìä Dataset Loading & Preprocessing for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### TEMPORARY:  Qdrant and Redis Database reset\n",
        "\n",
        "- For now I'm doing a data reset before each run (ü§∑‚Äç‚ôÇÔ∏è not best practice ü§∑‚Äç‚ôÄÔ∏è)\n",
        "\n",
        "```bash\n",
        "docker compose stop qdrant redis\n",
        "docker compose rm -f qdrant redis\n",
        "docker volume rm langchain-retrieval-methods_qdrant_data langchain-retrieval-methods_redis_data\n",
        "docker compose up -d qdrant redis\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "d794aa3a-234c-4fe7-b219-02e8b36c27ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "john_wick_1.csv already exists.\n",
            "john_wick_2.csv already exists.\n",
            "john_wick_3.csv already exists.\n",
            "john_wick_4.csv already exists.\n"
          ]
        }
      ],
      "source": [
        "# Set up a consistent data directory in the user's home directory\n",
        "from pathlib import Path\n",
        "DATA_DIR = Path.cwd() / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# URLs and filenames\n",
        "urls = [\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\", \"john_wick_1.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\", \"john_wick_2.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\", \"john_wick_3.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\", \"john_wick_4.csv\"),\n",
        "]\n",
        "\n",
        "# Download files if not already present\n",
        "for url, fname in urls:\n",
        "    file_path = DATA_DIR / fname\n",
        "    if not file_path.exists():\n",
        "        print(f\"Downloading {fname}...\")\n",
        "        r = requests.get(url)\n",
        "        r.raise_for_status()\n",
        "        file_path.write_bytes(r.content)\n",
        "    else:\n",
        "        print(f\"{fname} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "all_review_docs = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    loader = CSVLoader(\n",
        "        file_path=(DATA_DIR / f\"john_wick_{i}.csv\"),\n",
        "        metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "    )\n",
        "\n",
        "    movie_docs = loader.load()\n",
        "    for doc in movie_docs:\n",
        "\n",
        "        # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "        doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "        # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "        doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "        # newer movies have a more recent \"last_accessed_at\" (store as ISO string)\n",
        "        doc.metadata[\"last_accessed_at\"] = (datetime.now() - timedelta(days=4-i)).isoformat()\n",
        "\n",
        "    all_review_docs.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## üèóÔ∏è Building RAG Infrastructure: Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AX5XBOIltcvD"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore  # Updated import\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain_community.storage import RedisStore\n",
        "from langchain.storage import create_kv_docstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 1: Simple Vector Storage (Baseline)\n",
        "\n",
        "- creates the vector store using the all_review_docs Document object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6Hta5PoJlos"
      },
      "outputs": [],
      "source": [
        "baseline_vectorstore = QdrantVectorStore.from_documents(\n",
        "    all_review_docs,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_baseline\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 2: Hierarchical Storage (Parent-Child Architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Documents: Redis Key-Value Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CjIJlsjsrOSi"
      },
      "outputs": [],
      "source": [
        "redis_byte_store = RedisStore(redis_url=\"redis://localhost:6379\")\n",
        "parent_document_store = create_kv_docstore(redis_byte_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Child Records: Qdrant Vector Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Qdrant client\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True\n",
        ")\n",
        "\n",
        "# Check if the Qdrant collection exists\n",
        "if not cloud_client.collection_exists(\"johnwick_parent_children\"):\n",
        "    cloud_client.create_collection(\n",
        "        collection_name=\"johnwick_parent_children\",\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=1536,\n",
        "            distance=models.Distance.COSINE\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Construct the VectorStore using cloud client\n",
        "parent_children_vectorstore = QdrantVectorStore(\n",
        "    embedding=embeddings,\n",
        "    client=cloud_client,\n",
        "    collection_name=\"johnwick_parent_children\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retriever definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_children_vectorstore,\n",
        "    docstore=parent_document_store,\n",
        "    child_splitter=child_splitter,\n",
        ")\n",
        "\n",
        "parent_document_retriever.add_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 3: Vector Storage organized by Semantic Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RmMfpBIcF3dN"
      },
      "outputs": [],
      "source": [
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")\n",
        "\n",
        "semantic_documents = semantic_chunker.split_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_semantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaIgKvJmpjFu"
      },
      "source": [
        "## üéØ Core Learning: 7 Retrieval Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy Setup: Tracing & Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup langsmith tracing\n",
        "\n",
        "from langsmith import Client, traceable\n",
        "\n",
        "langsmith_client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "### Strategy 1: Naive Retrieval (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retriever = baseline_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "### Strategy 2: BM25 Retrieval (Keyword-Based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(all_review_docs)\n",
        "\n",
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "### Strategy 3: Contextual Compression (AI Reranking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "### Strategy 4: Multi-Query Retrieval (Query Expansion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever,\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "### Strategy 5: Parent Document Retrieval (Hierarchical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "### Strategy 6: Ensemble Retrieval (Combined Methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list,\n",
        "    weights=equal_weighting\n",
        ")\n",
        "\n",
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "### Strategy 7: Semantic Retrieval (Semantic Chunking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Performance Monitoring & Evaluation Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Traceable wrappers defined\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable(name=\"naive_retrieval\", run_type=\"chain\", metadata={\"method\":\"naive\"})\n",
        "def trace_naive_retrieval(question: str):\n",
        "    try:\n",
        "        result = naive_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"bm25_retrieval\", run_type=\"chain\", metadata={\"method\":\"bm25\"})\n",
        "def trace_bm25_retrieval(question: str):\n",
        "    try:\n",
        "        # Use the correct chain variable name here\n",
        "        res = bm25_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": res[\"response\"].content,\n",
        "            \"context_docs\": len(res[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"contextual_compression\", run_type=\"chain\", metadata={\"method\":\"compression\"})\n",
        "def trace_contextual_compression(question: str):\n",
        "    try:\n",
        "        result = contextual_compression_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"multi_query_retrieval\", run_type=\"chain\", metadata={\"method\":\"multi_query\"})\n",
        "def trace_multi_query_retrieval(question: str):\n",
        "    try:\n",
        "        result = multi_query_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"parent_document_retrieval\", run_type=\"chain\", metadata={\"method\":\"parent_document\"})\n",
        "def trace_parent_document_retrieval(question: str):\n",
        "    try:\n",
        "        result = parent_document_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"ensemble_retrieval\", run_type=\"chain\", metadata={\"method\":\"ensemble\"})\n",
        "def trace_ensemble_retrieval(question: str):\n",
        "    try:\n",
        "        result = ensemble_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"semantic_retrieval\", run_type=\"chain\", metadata={\"method\":\"semantic\"})\n",
        "def trace_semantic_retrieval(question: str):\n",
        "    try:\n",
        "        result = semantic_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "print(\"‚úÖ Traceable wrappers defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Execution & Real-Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All methods executed with tracing\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "question = \"Did people generally like John Wick?\"\n",
        "\n",
        "naive_retrieval_chain_response = trace_naive_retrieval(question)[\"response\"]\n",
        "bm25_retrieval_chain_response = trace_bm25_retrieval(question)[\"response\"]\n",
        "contextual_compression_retrieval_chain_response = trace_contextual_compression(question)[\"response\"]\n",
        "multi_query_retrieval_chain_response = trace_multi_query_retrieval(question)[\"response\"]\n",
        "semantic_retrieval_chain_response = trace_semantic_retrieval(question)[\"response\"]\n",
        "\n",
        "print(\"‚úÖ All methods executed with tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retrieval traces\n",
        "\n",
        "- broke these two out due to some serialization issues after adopting Redis\n",
        "- helped with troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain_response = trace_parent_document_retrieval(question)[\"response\"]\n",
        "ensemble_retrieval_chain_response = trace_ensemble_retrieval(question)[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tracers.langchain import wait_for_all_tracers\n",
        "\n",
        "# run after all your traceable calls\n",
        "wait_for_all_tracers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results Analysis & Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset: 'retrieval-method-comparison-20250603_212427_runs_ds'\n",
            "üöÄ Added 7 runs to dataset 'retrieval-method-comparison-20250603_212427_runs_ds'\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "# Assume langsmith_client is already initialized,\n",
        "# and `project_name` is set as above.\n",
        "\n",
        "# 1. Ensure the dataset exists or create it\n",
        "dataset_name = f\"{project_name}_runs_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"including method, response, context_docs, tokens, costs, durations, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset: {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset: {dataset.name!r}\")\n",
        "\n",
        "# 2. Fetch all top-level chain runs for the project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "))\n",
        "\n",
        "# 3. Ingest each run as an Example in the dataset\n",
        "for run in runs:\n",
        "    langsmith_client.create_example_from_run(\n",
        "        run=run,\n",
        "        dataset_id=dataset.id\n",
        "    )\n",
        "\n",
        "print(f\"üöÄ Added {len(runs)} runs to dataset {dataset.name!r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View LangGraph Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó View your dataset: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/ed3953e9-1178-4909-8723-0ddec664cc93\n"
          ]
        }
      ],
      "source": [
        "print(f\"üîó View your dataset: {dataset.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import timezone, datetime, timedelta\n",
        "\n",
        "# Fetch all top-level chain runs for our project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "    start_time=datetime.now(timezone.utc) - timedelta(hours=1)  # last hour\n",
        "))\n",
        "\n",
        "# Build a record per run, pulling in every field ‚Äúas is‚Äù\n",
        "records = []\n",
        "for run in runs:\n",
        "    records.append({\n",
        "        \"run_id\":          str(run.id),\n",
        "        \"name\":             run.name,\n",
        "        \"method\":           run.metadata.get(\"method\"),\n",
        "        \"status\":           run.status,\n",
        "        \"start_time\":       run.start_time,\n",
        "        \"end_time\":         run.end_time,\n",
        "        \"duration_ms\":      ((run.end_time - run.start_time).total_seconds()*1000)\n",
        "                              if run.start_time and run.end_time else None,\n",
        "        # cost & tokens\n",
        "        \"prompt_tokens\":    run.prompt_tokens,\n",
        "        \"completion_tokens\":run.completion_tokens,\n",
        "        \"total_tokens\":     run.total_tokens,\n",
        "        \"prompt_cost\":      run.prompt_cost,\n",
        "        \"completion_cost\":  run.completion_cost,\n",
        "        \"total_cost\":       run.total_cost,\n",
        "        # errors\n",
        "        \"error\":            run.error,                                   \n",
        "        \"wrapper_error\":    (run.outputs or {}).get(\"error\"),\n",
        "        # wrapper outputs\n",
        "        \"response\":         (run.outputs or {}).get(\"response\"),\n",
        "        \"context_docs\":     (run.outputs or {}).get(\"context_docs\"),\n",
        "    })\n",
        "\n",
        "df_runs = pd.DataFrame.from_records(records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Core Learning: 7 Retrieval Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>name</th>\n",
              "      <th>method</th>\n",
              "      <th>status</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>prompt_cost</th>\n",
              "      <th>completion_cost</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>error</th>\n",
              "      <th>wrapper_error</th>\n",
              "      <th>response</th>\n",
              "      <th>context_docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>710e86cb-68ff-4e32-9c8b-6055b8706e87</td>\n",
              "      <td>ensemble_retrieval</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:42:11.857757</td>\n",
              "      <td>2025-06-04 04:42:20.408256</td>\n",
              "      <td>8550.499</td>\n",
              "      <td>6008</td>\n",
              "      <td>304</td>\n",
              "      <td>6312</td>\n",
              "      <td>0.0024032</td>\n",
              "      <td>0.0004864</td>\n",
              "      <td>0.0028896</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the reviews provided, people generall...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039d3c8-23b4-4a5c-aa97-c9b522e87205</td>\n",
              "      <td>parent_document_retrieval</td>\n",
              "      <td>parent_document</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:42:06.798463</td>\n",
              "      <td>2025-06-04 04:42:11.857406</td>\n",
              "      <td>5058.943</td>\n",
              "      <td>784</td>\n",
              "      <td>123</td>\n",
              "      <td>907</td>\n",
              "      <td>0.0003136</td>\n",
              "      <td>0.0001968</td>\n",
              "      <td>0.0005104</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided context, people generall...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3478c301-7af0-4af6-bda8-5b70c038bf76</td>\n",
              "      <td>semantic_retrieval</td>\n",
              "      <td>semantic</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:42:02.732691</td>\n",
              "      <td>2025-06-04 04:42:06.791275</td>\n",
              "      <td>4058.584</td>\n",
              "      <td>3193</td>\n",
              "      <td>118</td>\n",
              "      <td>3311</td>\n",
              "      <td>0.0012772</td>\n",
              "      <td>0.0001888</td>\n",
              "      <td>0.001466</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The rev...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a0f57579-db19-4111-9969-45a7fce73b68</td>\n",
              "      <td>multi_query_retrieval</td>\n",
              "      <td>multi_query</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:41:56.646118</td>\n",
              "      <td>2025-06-04 04:42:02.732316</td>\n",
              "      <td>6086.198</td>\n",
              "      <td>5384</td>\n",
              "      <td>257</td>\n",
              "      <td>5641</td>\n",
              "      <td>0.0021536</td>\n",
              "      <td>0.0004112</td>\n",
              "      <td>0.0025648</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the reviews and ratings in the provid...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>273aa83a-0113-49bb-a537-353cf03c7834</td>\n",
              "      <td>contextual_compression</td>\n",
              "      <td>compression</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:41:53.579192</td>\n",
              "      <td>2025-06-04 04:41:56.645332</td>\n",
              "      <td>3066.140</td>\n",
              "      <td>1567</td>\n",
              "      <td>96</td>\n",
              "      <td>1663</td>\n",
              "      <td>0.0006268</td>\n",
              "      <td>0.0001536</td>\n",
              "      <td>0.0007804</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, based on the reviews provided, people gen...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3dd6454f-da7a-45e5-ac1e-cf33158e3bd0</td>\n",
              "      <td>bm25_retrieval</td>\n",
              "      <td>bm25</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:41:51.103587</td>\n",
              "      <td>2025-06-04 04:41:53.578617</td>\n",
              "      <td>2475.030</td>\n",
              "      <td>1292</td>\n",
              "      <td>178</td>\n",
              "      <td>1470</td>\n",
              "      <td>0.0005168</td>\n",
              "      <td>0.0002848</td>\n",
              "      <td>0.0008016</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>People's opinions about John Wick appear mixed...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d187bf89-9dc7-4ab4-9883-af655696c197</td>\n",
              "      <td>naive_retrieval</td>\n",
              "      <td>naive</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-06-04 04:41:47.882958</td>\n",
              "      <td>2025-06-04 04:41:51.102481</td>\n",
              "      <td>3219.523</td>\n",
              "      <td>3794</td>\n",
              "      <td>159</td>\n",
              "      <td>3953</td>\n",
              "      <td>0.0015176</td>\n",
              "      <td>0.0002544</td>\n",
              "      <td>0.001772</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked the movie *John Wi...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 run_id                       name  \\\n",
              "0  710e86cb-68ff-4e32-9c8b-6055b8706e87         ensemble_retrieval   \n",
              "1  4039d3c8-23b4-4a5c-aa97-c9b522e87205  parent_document_retrieval   \n",
              "2  3478c301-7af0-4af6-bda8-5b70c038bf76         semantic_retrieval   \n",
              "3  a0f57579-db19-4111-9969-45a7fce73b68      multi_query_retrieval   \n",
              "4  273aa83a-0113-49bb-a537-353cf03c7834     contextual_compression   \n",
              "5  3dd6454f-da7a-45e5-ac1e-cf33158e3bd0             bm25_retrieval   \n",
              "6  d187bf89-9dc7-4ab4-9883-af655696c197            naive_retrieval   \n",
              "\n",
              "            method   status                 start_time  \\\n",
              "0         ensemble  success 2025-06-04 04:42:11.857757   \n",
              "1  parent_document  success 2025-06-04 04:42:06.798463   \n",
              "2         semantic  success 2025-06-04 04:42:02.732691   \n",
              "3      multi_query  success 2025-06-04 04:41:56.646118   \n",
              "4      compression  success 2025-06-04 04:41:53.579192   \n",
              "5             bm25  success 2025-06-04 04:41:51.103587   \n",
              "6            naive  success 2025-06-04 04:41:47.882958   \n",
              "\n",
              "                    end_time  duration_ms  prompt_tokens  completion_tokens  \\\n",
              "0 2025-06-04 04:42:20.408256     8550.499           6008                304   \n",
              "1 2025-06-04 04:42:11.857406     5058.943            784                123   \n",
              "2 2025-06-04 04:42:06.791275     4058.584           3193                118   \n",
              "3 2025-06-04 04:42:02.732316     6086.198           5384                257   \n",
              "4 2025-06-04 04:41:56.645332     3066.140           1567                 96   \n",
              "5 2025-06-04 04:41:53.578617     2475.030           1292                178   \n",
              "6 2025-06-04 04:41:51.102481     3219.523           3794                159   \n",
              "\n",
              "   total_tokens prompt_cost completion_cost total_cost error wrapper_error  \\\n",
              "0          6312   0.0024032       0.0004864  0.0028896  None          None   \n",
              "1           907   0.0003136       0.0001968  0.0005104  None          None   \n",
              "2          3311   0.0012772       0.0001888   0.001466  None          None   \n",
              "3          5641   0.0021536       0.0004112  0.0025648  None          None   \n",
              "4          1663   0.0006268       0.0001536  0.0007804  None          None   \n",
              "5          1470   0.0005168       0.0002848  0.0008016  None          None   \n",
              "6          3953   0.0015176       0.0002544   0.001772  None          None   \n",
              "\n",
              "                                            response  context_docs  \n",
              "0  Based on the reviews provided, people generall...            18  \n",
              "1  Based on the provided context, people generall...             3  \n",
              "2  Yes, people generally liked John Wick. The rev...            10  \n",
              "3  Based on the reviews and ratings in the provid...            15  \n",
              "4  Yes, based on the reviews provided, people gen...             3  \n",
              "5  People's opinions about John Wick appear mixed...             4  \n",
              "6  Yes, people generally liked the movie *John Wi...            10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df_runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Retrieval Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset 'retrieval-method-comparison-20250603_212427_runs_custom_ds'\n",
            "‚úÖ Added 7 runs to dataset 'retrieval-method-comparison-20250603_212427_runs_custom_ds'\n",
            "üîó Dataset URL: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/9aa9f128-ca48-4077-bbe7-27f57f976307\n"
          ]
        }
      ],
      "source": [
        "# 1) Create or load the dataset\n",
        "dataset_name = f\"{project_name}_runs_custom_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"capturing inputs, outputs, tokens, costs, duration, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset {dataset.name!r}\")\n",
        "\n",
        "# 2) Bulk‚Äêingest each run as an Example\n",
        "for _, row in df_runs.iterrows():\n",
        "    langsmith_client.create_example(\n",
        "        dataset_id=dataset.id,\n",
        "        inputs={\n",
        "            \"run_id\": row[\"run_id\"],\n",
        "            \"method\": row[\"method\"],\n",
        "        },\n",
        "        outputs={\n",
        "            # include whichever outputs you care about:\n",
        "            \"response\": row[\"response\"],\n",
        "            \"context_docs\": int(row[\"context_docs\"]),\n",
        "        },\n",
        "        metadata={\n",
        "            # include metrics & error info as metadata\n",
        "            \"status\": row[\"status\"],\n",
        "            \"duration_ms\": float(row[\"duration_ms\"]),\n",
        "            \"prompt_tokens\": int(row[\"prompt_tokens\"]),\n",
        "            \"completion_tokens\": int(row[\"completion_tokens\"]),\n",
        "            \"total_tokens\": int(row[\"total_tokens\"]),\n",
        "            \"prompt_cost\": float(row[\"prompt_cost\"]),\n",
        "            \"completion_cost\": float(row[\"completion_cost\"]),\n",
        "            \"total_cost\": float(row[\"total_cost\"]),\n",
        "            # optionally include error\n",
        "            **({\"error\": row[\"error\"]} if pd.notna(row.get(\"error\")) else {}),\n",
        "            **({\"wrapper_error\": row[\"wrapper_error\"]} if pd.notna(row.get(\"wrapper_error\")) else {}),\n",
        "        }\n",
        "    )\n",
        "print(f\"‚úÖ Added {len(df_runs)} runs to dataset {dataset.name!r}\")\n",
        "print(\"üîó Dataset URL:\", dataset.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYuh2V1vHY6N"
      },
      "source": [
        "## üõ†Ô∏è Exploration Tools & Cleanup Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List of Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYbdWnVHct-",
        "outputId": "11cc0bc2-434d-4512-99ed-870b64c09357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['ambrose_lake_covenant', 'johnwick_semantic', 'pg_jsonb_limited_docs', 'johnwick_baseline', 'airbnb_pdf_rec_1000_200_images', 'mcp-anthropic-desktop', 'mcp-nsclc', 'johnwick_parent_children']\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant collections\n",
        "\n",
        "existing = [c.name for c in cloud_client.get_collections().collections]\n",
        "\n",
        "print(type(existing))\n",
        "print(existing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qdrant info by Storage Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaFQTs_MzlG",
        "outputId": "7fb85947-3663-4a83-a89f-b06fcf89d772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== baseline ===\n",
            "Exists?       True\n",
            "Point count:  count=100\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== parent ===\n",
            "Exists?       True\n",
            "Point count:  count=4817\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== semantic ===\n",
            "Exists?       True\n",
            "Point count:  count=179\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant vector store collection metadata\n",
        "\n",
        "stores = {\n",
        "    \"baseline\": baseline_vectorstore,\n",
        "    \"parent\":  parent_children_vectorstore,\n",
        "    \"semantic\": semantic_vectorstore,\n",
        "}\n",
        "\n",
        "for name, vs in stores.items():\n",
        "    client = vs.client\n",
        "    col    = vs.collection_name\n",
        "    print(f\"=== {name} ===\")\n",
        "    # 1) Existence check\n",
        "    print(\"Exists?      \", client.collection_exists(col))\n",
        "    # 2) Point count\n",
        "    print(\"Point count: \", client.count(collection_name=col))\n",
        "    # 3) Full collection info\n",
        "    desc   = client.get_collection(collection_name=col)\n",
        "    params = desc.config.params\n",
        "\n",
        "    # ‚Äî Vector dims & metric\n",
        "    vec_field = params.vectors\n",
        "    if isinstance(vec_field, dict):\n",
        "        # multi-vector mode: pick the first VectorParams\n",
        "        vp = next(iter(vec_field.values()))\n",
        "    else:\n",
        "        # single-vector mode: vectors is itself a VectorParams\n",
        "        vp = vec_field\n",
        "    print(\"Dim / metric:\", vp.size, \"/\", vp.distance)\n",
        "\n",
        "    # ‚Äî Shard count & replication factor live on params\n",
        "    print(\"Shards / repl:\", params.shard_number, \"/\", params.replication_factor)\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Redis info for Parent Document Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDXX48ENcaEY",
        "outputId": "3d78a55f-2fc1-49c8-aee1-ffc3ffbf91a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in store: 100\n",
            "Metadata fields present: ['Author', 'Movie_Title', 'Rating', 'Review_Date', 'Review_Title', 'Review_Url', 'last_accessed_at', 'row', 'source']\n",
            "Metadata field types:\n",
            " ‚Ä¢ Author: types=['str'], sample='statuskuo'\n",
            " ‚Ä¢ Review_Date: types=['str'], sample='27 March 2023'\n",
            " ‚Ä¢ Rating: types=['int'], sample=4\n",
            " ‚Ä¢ Review_Url: types=['str'], sample='/review/rw8954612/?ref_=tt_urv'\n",
            " ‚Ä¢ Movie_Title: types=['str'], sample='John Wick 4'\n",
            " ‚Ä¢ source: types=['str'], sample='/home/donbr/aim/langchain-retrieval-methods/data/john_wick_4.csv'\n",
            " ‚Ä¢ Review_Title: types=['str'], sample=' Sound And Fury Adds Up To Nothing\\n'\n",
            " ‚Ä¢ row: types=['int'], sample=23\n",
            " ‚Ä¢ last_accessed_at: types=['str'], sample='2025-06-03T21:25:17.622793'\n",
            "Doc 1 (ID=75148f43-a0fb-423b-b84a-d9c4cffeb738): 313 characters\n",
            "Doc 2 (ID=53460586-81c2-462e-ba64-8ce384b4be93): 732 characters\n",
            "Doc 3 (ID=1cfe047e-ba34-4875-9e07-5c09d9831c29): 398 characters\n",
            "Doc 4 (ID=163fb8aa-4940-46cd-b064-87764c4ad6bc): 403 characters\n",
            "Doc 5 (ID=9167e9d1-6b95-4870-938a-f172be1c6732): 338 characters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assume `parent_document_store` already has docs via ParentDocumentRetriever\n",
        "#  (i.e. you already did retriever.add_documents(...) or similar)\n",
        "\n",
        "# 1) List all stored keys (document IDs)\n",
        "all_keys = list(parent_document_store.yield_keys())\n",
        "print(f\"Total documents in store: {len(all_keys)}\")\n",
        "# print(\"Document IDs:\", all_keys)\n",
        "\n",
        "# 2) Fetch all Document objects\n",
        "docs = parent_document_store.mget(all_keys)\n",
        "\n",
        "# 3) Examine metadata schema\n",
        "#    Collect all metadata field names across docs\n",
        "all_fields = set()\n",
        "for doc in docs:\n",
        "    all_fields.update(doc.metadata.keys())\n",
        "\n",
        "print(f\"Metadata fields present: {sorted(all_fields)}\")\n",
        "\n",
        "# 4) Show per-field value types and a sample value\n",
        "field_types = {field: set() for field in all_fields}\n",
        "for doc in docs:\n",
        "    for field, val in doc.metadata.items():\n",
        "        field_types[field].add(type(val).__name__)\n",
        "\n",
        "print(\"Metadata field types:\")\n",
        "for field, types in field_types.items():\n",
        "    sample = next((d.metadata[field] for d in docs if field in d.metadata), None)\n",
        "    print(f\" ‚Ä¢ {field}: types={sorted(types)}, sample={sample!r}\")\n",
        "\n",
        "# 5) (Optional) Print out first N docs‚Äô text lengths to gauge ‚Äúdimensions‚Äù\n",
        "for i, doc in enumerate(docs[:5], 1):\n",
        "    text_len = len(doc.page_content)\n",
        "    print(f\"Doc {i} (ID={all_keys[i-1]}): {text_len} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCKwiiOuHi9p"
      },
      "source": [
        "### Delete Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Pe_COpbsHcB7"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# initialize client (cloud or on-prem)\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        ")\n",
        "\n",
        "# create conditional deletion flag\n",
        "delete_collection = False\n",
        "\n",
        "if delete_collection:\n",
        "    # list of collections to drop\n",
        "    collections_to_reset = [\n",
        "        \"johnwick_baseline\",\n",
        "        \"johnwick_parent_children\",\n",
        "        \"johnwick_semantic\",\n",
        "    ]\n",
        "\n",
        "    for col_name in collections_to_reset:\n",
        "        # guard against missing collections\n",
        "        if cloud_client.collection_exists(col_name):\n",
        "            cloud_client.delete_collection(\n",
        "                collection_name=col_name,\n",
        "                timeout=60,  # seconds\n",
        "            )\n",
        "            print(f\"Deleted collection: {col_name}\")\n",
        "        else:\n",
        "            print(f\"Collection not found (skipped): {col_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KWMPESVcFT_"
      },
      "source": [
        "### Response Object validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHCFk-PajS6t",
        "outputId": "e77ca077-2d16-41d5-d5dc-fb5036f20e65"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked the movie *John Wick*. The reviews are mostly positive, highlighting the stylish and slick action sequences, Keanu Reeves' confident performance, and the film's engaging, straightforward plot. For example:\n",
            "\n",
            "- One reviewer called it \"the coolest action film you'll see all year\" and praised its intense action and fast-paced story.\n",
            "- Another described it as \"something special,\" with smooth action sequences and a unique criminal underworld.\n",
            "- Multiple reviews recommend it highly to action fans, noting that it offers brutal, yet fun entertainment.\n",
            "- Although there was at least one more mixed or critical review mentioning it felt generic compared to other action thrillers, the overall sentiment is very favorable.\n",
            "\n",
            "In summary, *John Wick* was well received and considered a standout action film by most reviewers.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "People's opinions about John Wick appear mixed based on the reviews provided. \n",
            "\n",
            "- The first John Wick movie generally received very positive reviews, with praise for its stylish action, clear simple plot, and Keanu Reeves' performance. For example, one reviewer gave it a 10/10 and called it a \"must see for action fans,\" while another gave it an 8, appreciating its kinetic action and relatable hero.\n",
            "\n",
            "- However, later installments received more criticism. John Wick 3 was described negatively by one reviewer as \"boring, dull,\" and \"mindless, plotless,\" with only 1/10 rating. Similarly, John Wick 4 was called the weakest in the series by one reviewer, with many action scenes but little meaningful plot.\n",
            "\n",
            "In summary, while the original John Wick movie was generally liked and praised, some later sequels had more divided or negative receptions.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, based on the reviews provided, people generally liked the first John Wick film. Reviewers praised Keanu Reeves' performance, the slick and well-choreographed action sequences, and the film's stylish and engaging world. They described it as one of the best action films of the year and appreciated its unique approach compared to typical action movies. While there is a mention that the magic was gone by the third film for one reviewer, the first film received very positive feedback overall.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the reviews and ratings in the provided context, people generally liked the John Wick series, especially the first three films. The first John Wick movie received high praise for its stylish action, fast pace, and Keanu Reeves' performance, with several reviewers giving it ratings of 8, 9, or even 10 out of 10. The reviews highlight its unique and well-choreographed action sequences, cool atmosphere, and fun, brutal revenge story.\n",
            "\n",
            "The series as a whole is described as consistent and well-received, with all the first three films holding similar IMDb ratings around 7.4/10. The fourth installment is noted by some reviewers as the best of the series and praised for its intense action and set pieces, though there are also some dissenting opinions criticizing the plot and repetitiveness.\n",
            "\n",
            "In summary:\n",
            "- Most reviews are very positive.\n",
            "- The series is recognized for raising the bar in action films.\n",
            "- Keanu Reeves' portrayal of John Wick is widely appreciated.\n",
            "- Some negative opinions exist but are in the minority.\n",
            "\n",
            "Therefore, people generally did like John Wick.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided context, people generally liked John Wick. For example, one reviewer praised the first John Wick movie highly, appreciating the action and emotional setup. Another reviewer mentioned that the John Wick series has remained consistent and well-received, even saying that \"John Wick: Chapter 4\" is the best in the series. However, there are some negative opinions as well, such as one reviewer who strongly disliked John Wick 4, calling it \"horrible\" and criticizing the plot and fight scenes.\n",
            "\n",
            "Overall, while individual opinions vary, the general sentiment toward the John Wick series appears to be positive.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the reviews provided, people generally liked the first **John Wick** film. Many reviews praise its stylish action sequences, Keanu Reeves' performance, and the unique world-building. For example:\n",
            "\n",
            "- One reviewer called it \"something special,\" highlighting the smooth action choreography and the cool criminal underworld setting.\n",
            "- Another review described it as \"the best action film of the year\" and \"insanely fun, violently brutal,\" appreciating Reeves' confident performance.\n",
            "- It was also noted as \"kinetic, concise, and stylish\" and recommended strongly to action fans.\n",
            "- Even though some found the plot simple or the movie somewhat generic, the overall sentiment about the first film tends to be positive, emphasizing the high-quality action and excitement it delivers.\n",
            "\n",
            "However, there are some mixed or negative opinions, especially on later sequels (like John Wick 3 and 4), where some reviewers felt the films became overly violent, lose plot depth, or become repetitive. But for the original John Wick film specifically, the consensus from these reviews shows that it was well-liked and appreciated, particularly for its action and Keanu Reeves‚Äô role.\n",
            "\n",
            "**In summary:** Yes, people generally liked the first John Wick movie, considering it a standout action film with stylish and well-choreographed sequences, and a strong lead performance by Keanu Reeves.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The reviews for the first film are very positive, praising its stylish action, smooth choreography, and Keanu Reeves' performance. Reviewers describe it as one of the best action films in recent years, highlighting its brisk pace, intense action sequences, and unique world-building. The franchise as a whole has been well received, with some noting that even the later installments maintain high quality and deliver exciting action, though there are mixed feelings about the third film for some viewers. Overall, the John Wick series is regarded as entertaining and highly regarded among action fans.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to response objects\n",
        "responses = {\n",
        "    \"Naive Retrieval Chain Response\":              naive_retrieval_chain_response,\n",
        "    \"BM25 Retrieval Chain Response\":               bm25_retrieval_chain_response,\n",
        "    \"Contextual Compression Chain Response\":       contextual_compression_retrieval_chain_response,\n",
        "    \"Multi-Query Retrieval Chain Response\":        multi_query_retrieval_chain_response,\n",
        "    \"Parent Document Retrieval Chain Response\":    parent_document_retrieval_chain_response,\n",
        "    \"Ensemble Retrieval Chain Response\":           ensemble_retrieval_chain_response,\n",
        "    \"Semantic Retrieval Chain Response\":           semantic_retrieval_chain_response,\n",
        "}\n",
        "\n",
        "for header, resp in responses.items():\n",
        "    display(Markdown(f\"## {header}\\n\"))\n",
        "    print(\"\\n\")\n",
        "    print(resp)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGRzkNHjPUd"
      },
      "source": [
        "### Retrieval Chain validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vZOd4DL9NS3k",
        "outputId": "860d77fb-83d0-4ec7-a8d3-27cb66d8ae60"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f0b09e7d990>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f0b0821f050>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10})),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser()),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b50c9e250>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7f0b8ae3c790>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f0b09ff6810>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f0b09e7d990>), VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10}), ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b50c9e250>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7f0b8ae3c790>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f0b09ff6810>), ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f0b0821f050>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10})), MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b5121e1d0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser())], weights=[0.2, 0.2, 0.2, 0.2, 0.2]),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f0b4c117090>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f0b8b40ff90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f0b8afb6310>, root_client=<openai.OpenAI object at 0x7f0b8bb20650>, root_async_client=<openai.AsyncOpenAI object at 0x7f0b8b49c350>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to chains\n",
        "chains = {\n",
        "    \"Naive Retrieval\":              naive_retrieval_chain,\n",
        "    \"BM25 Retrieval\":               bm25_retrieval_chain,\n",
        "    \"Contextual Compression\":       contextual_compression_retrieval_chain,\n",
        "    \"Multi-Query Retrieval\":        multi_query_retrieval_chain,\n",
        "    \"Parent Document Retrieval\":    parent_document_retrieval_chain,\n",
        "    \"Ensemble Retrieval\":           ensemble_retrieval_chain,\n",
        "    \"Semantic Retrieval\":           semantic_retrieval_chain,\n",
        "}\n",
        "\n",
        "for title, chain in chains.items():\n",
        "    display(Markdown(f\"## {title}\\n\"))\n",
        "    print(chain)\n",
        "    # print(chain.get_graph().draw_ascii())\n",
        "    print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
