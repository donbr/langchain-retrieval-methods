{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Welcome to the **LangChain Retrieval Methods** notebook.  \n",
        "In this tutorial you will:\n",
        "\n",
        "1. **Load** a small corpus of John Wick movie reviews.\n",
        "2. **Explore** seven distinct retrieval strategies:\n",
        "   - Naive (whole‐document vectors)\n",
        "   - BM25 (keyword matching)\n",
        "   - Contextual Compression (reranking)\n",
        "   - Multi‐Query (query expansion)\n",
        "   - Parent Document (hierarchical chunks)\n",
        "   - Ensemble (fusion of methods)\n",
        "   - Semantic (boundary‐aware chunking)\n",
        "\n",
        "3. **Compare** each method across:\n",
        "   - Retrieval **quality** (recall@k, qualitative response patterns)\n",
        "   - **Latency** (ms per query)\n",
        "   - **Cost** (API/token usage)\n",
        "   - **Resource footprint** (index size & shape)\n",
        "\n",
        "4. **Visualize** key metrics and response examples to understand trade-offs.\n",
        "\n",
        "By the end of the notebook, you’ll know:\n",
        "- When to **start simple** (Naive or BM25) versus **scale up** (Ensemble or Semantic).\n",
        "- How context-window advances (4 K → 32 K → 128 K) and loader-splitter decoupling shape modern RAG architectures.\n",
        "- Practical tips for **production readiness**, including index sharding, zero-downtime reindexes, and drift monitoring.\n",
        "\n",
        "> **Prerequisites**  \n",
        "> - Python 3.11 environment (see Quickstart)  \n",
        "> - Access to a Qdrant Cloud instance (with API key)  \n",
        "> - OpenAI API credentials for embedding & reranking  \n",
        "\n",
        "Run the cells in order, or jump to the section that interests you. Let’s get started!  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MkgFAXWVW3wm"
      },
      "outputs": [],
      "source": [
        "#!uv pip install -qU langchain langchain-community langchain-experimental langchain-openai langchain-qdrant langchain-cohere rank_bm25 qdrant-client langsmith grandalf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Build a dynamic project name (e.g. include timestamp)\n",
        "project_name = f\"retrieval-method-comparison-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"COHERE_API_KEY\"] = os.getenv('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = project_name\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv('LANGSMITH_API_KEY')\n",
        "\n",
        "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "QDRANT_API_URL = os.getenv(\"QDRANT_API_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "d794aa3a-234c-4fe7-b219-02e8b36c27ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "john_wick_1.csv already exists.\n",
            "john_wick_2.csv already exists.\n",
            "john_wick_3.csv already exists.\n",
            "john_wick_4.csv already exists.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"### Data Preparation\"\"\"\n",
        "\n",
        "# Set up a consistent data directory in the user's home directory\n",
        "DATA_DIR = Path.home() / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# URLs and filenames\n",
        "urls = [\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\", \"john_wick_1.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\", \"john_wick_2.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\", \"john_wick_3.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\", \"john_wick_4.csv\"),\n",
        "]\n",
        "\n",
        "# Download files if not already present\n",
        "for url, fname in urls:\n",
        "    file_path = DATA_DIR / fname\n",
        "    if not file_path.exists():\n",
        "        print(f\"Downloading {fname}...\")\n",
        "        r = requests.get(url)\n",
        "        r.raise_for_status()\n",
        "        file_path.write_bytes(r.content)\n",
        "    else:\n",
        "        print(f\"{fname} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)\n",
        "\n",
        "parent_docs = documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFoVHtS8hrr",
        "outputId": "f26697eb-e3eb-4d74-d10f-715c0771185d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of parent_docs: 100\n",
            "Length of documents: 100\n"
          ]
        }
      ],
      "source": [
        "# display length of parent_docs and docs\n",
        "print(f\"Length of parent_docs: {len(parent_docs)}\")\n",
        "print(f\"Length of documents: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Setup Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AX5XBOIltcvD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_qdrant import QdrantVectorStore  # Updated import\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d6Hta5PoJlos"
      },
      "outputs": [],
      "source": [
        "# 1. Main vectorstore using qdrant cloud\n",
        "baseline_vectorstore = QdrantVectorStore.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_baseline\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CjIJlsjsrOSi"
      },
      "outputs": [],
      "source": [
        "# 2. Parent document setup with qdrant cloud client\n",
        "\n",
        "# Initialize cloud client\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True\n",
        ")\n",
        "\n",
        "# Check if the collection exists\n",
        "if not cloud_client.collection_exists(\"johnwick_parent\"):\n",
        "    cloud_client.create_collection(\n",
        "        collection_name=\"johnwick_parent\",\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=1536,\n",
        "            distance=models.Distance.COSINE\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Construct the VectorStore using cloud client\n",
        "parent_vectorstore = QdrantVectorStore(\n",
        "    embedding=embeddings,\n",
        "    client=cloud_client,\n",
        "    collection_name=\"johnwick_parent\",\n",
        ")\n",
        "\n",
        "store = InMemoryStore()\n",
        "\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")\n",
        "\n",
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RmMfpBIcF3dN"
      },
      "outputs": [],
      "source": [
        "# 3. Semantic chunking using qdrant cloud\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")\n",
        "\n",
        "semantic_documents = semantic_chunker.split_documents(documents)\n",
        "\n",
        "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_semantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaIgKvJmpjFu"
      },
      "source": [
        "## Retrievers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup langsmith tracing\n",
        "\n",
        "from langsmith import Client, traceable\n",
        "\n",
        "langsmith_client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "### Naive Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retriever = baseline_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "### BM25 Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)\n",
        "\n",
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "### Contextual Compression Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "### Multi-Query Retriever\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever,\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "### Parent Document Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "### Ensemble Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list,\n",
        "    weights=equal_weighting\n",
        ")\n",
        "\n",
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "### Semantic Retriever - using semantically chunked vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Traceable Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Traceable wrappers defined\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable(name=\"naive_retrieval\", run_type=\"chain\", metadata={\"method\":\"naive\"})\n",
        "def trace_naive_retrieval(question: str):\n",
        "    try:\n",
        "        result = naive_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"bm25_retrieval\", run_type=\"chain\", metadata={\"method\":\"bm25\"})\n",
        "def trace_bm25_retrieval(question: str):\n",
        "    try:\n",
        "        # Use the correct chain variable name here\n",
        "        res = bm25_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": res[\"response\"].content,\n",
        "            \"context_docs\": len(res[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"contextual_compression\", run_type=\"chain\", metadata={\"method\":\"compression\"})\n",
        "def trace_contextual_compression(question: str):\n",
        "    try:\n",
        "        result = contextual_compression_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"multi_query_retrieval\", run_type=\"chain\", metadata={\"method\":\"multi_query\"})\n",
        "def trace_multi_query_retrieval(question: str):\n",
        "    try:\n",
        "        result = multi_query_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"parent_document_retrieval\", run_type=\"chain\", metadata={\"method\":\"parent_document\"})\n",
        "def trace_parent_document_retrieval(question: str):\n",
        "    try:\n",
        "        result = parent_document_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"ensemble_retrieval\", run_type=\"chain\", metadata={\"method\":\"ensemble\"})\n",
        "def trace_ensemble_retrieval(question: str):\n",
        "    try:\n",
        "        result = ensemble_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"semantic_retrieval\", run_type=\"chain\", metadata={\"method\":\"semantic\"})\n",
        "def trace_semantic_retrieval(question: str):\n",
        "    try:\n",
        "        result = semantic_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "print(\"✅ Traceable wrappers defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run All Traceable Retrievals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All methods executed with tracing\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "question = \"Did people generally like John Wick?\"\n",
        "\n",
        "naive_retrieval_chain_response = trace_naive_retrieval(question)[\"response\"]\n",
        "bm25_retrieval_chain_response = trace_bm25_retrieval(question)[\"response\"]\n",
        "contextual_compression_retrieval_chain_response = trace_contextual_compression(question)[\"response\"]\n",
        "multi_query_retrieval_chain_response = trace_multi_query_retrieval(question)[\"response\"]\n",
        "parent_document_retrieval_chain_response = trace_parent_document_retrieval(question)[\"response\"]\n",
        "ensemble_retrieval_chain_response = trace_ensemble_retrieval(question)[\"response\"]\n",
        "semantic_retrieval_chain_response = trace_semantic_retrieval(question)[\"response\"]\n",
        "\n",
        "print(\"✅ All methods executed with tracing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tracers.langchain import wait_for_all_tracers\n",
        "\n",
        "# … after all your traceable calls …\n",
        "wait_for_all_tracers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available attributes in a run: ['Config', '__abstractmethods__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_host_url', '_init_private_attributes', '_iter', 'app_path', 'attachments', 'child_run_ids', 'child_runs', 'completion_cost', 'completion_tokens', 'construct', 'copy', 'dict', 'dotted_order', 'end_time', 'error', 'events', 'extra', 'feedback_stats', 'first_token_time', 'from_orm', 'id', 'in_dataset', 'inputs', 'json', 'manifest_id', 'metadata', 'name', 'outputs', 'parent_run_id', 'parent_run_ids', 'parse_file', 'parse_obj', 'parse_raw', 'prompt_cost', 'prompt_tokens', 'reference_example_id', 'revision_id', 'run_type', 'schema', 'schema_json', 'serialized', 'session_id', 'start_time', 'status', 'tags', 'total_cost', 'total_tokens', 'trace_id', 'update_forward_refs', 'url', 'validate']\n",
            "\n",
            "Example run metadata: {'LANGSMITH_PROJECT': 'retrieval-method-comparison-20250524_012506', 'LANGSMITH_TRACING': 'true', 'ls_method': 'traceable', 'method': 'semantic', 'revision_id': 'b0c00e9-dirty', 'ls_run_depth': 0}\n",
            "\n",
            "Example run outputs: None\n"
          ]
        }
      ],
      "source": [
        "# LangSmith Run Debugging information (for the first run)\n",
        "\n",
        "root_runs_gen = langsmith_client.list_runs(\n",
        "  project_name=project_name,\n",
        "  is_root=True,\n",
        "  run_type=\"chain\"      # only top-level chain runs\n",
        ")\n",
        "\n",
        "# First, let's examine the structure of a single run before materializing all runs\n",
        "first_run = next(root_runs_gen)\n",
        "print(\"Available attributes in a run:\", dir(first_run))\n",
        "print(\"\\nExample run metadata:\", first_run.metadata)\n",
        "print(\"\\nExample run outputs:\", first_run.outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a LangSmith Dataset to preserve the memories!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created dataset: 'retrieval-method-comparison-20250524_012506_runs_ds'\n",
            "🚀 Added 7 runs to dataset 'retrieval-method-comparison-20250524_012506_runs_ds'\n",
            "🔗 View your dataset: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/5c0a4bfd-9011-4f3d-98a8-3608d9fcac7c\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## Ingest All Root Chain Runs into LangSmith Dataset\n",
        "\n",
        "# %%\n",
        "from langsmith import Client\n",
        "\n",
        "# Assume langsmith_client is already initialized,\n",
        "# and `project_name` is set as above.\n",
        "\n",
        "# 1. Ensure the dataset exists or create it\n",
        "dataset_name = f\"{project_name}_runs_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"including method, response, context_docs, tokens, costs, durations, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"✅ Created dataset: {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"ℹ️  Using existing dataset: {dataset.name!r}\")\n",
        "\n",
        "# 2. Fetch all top-level chain runs for the project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "))\n",
        "\n",
        "# 3. Ingest each run as an Example in the dataset\n",
        "for run in runs:\n",
        "    langsmith_client.create_example_from_run(\n",
        "        run=run,\n",
        "        dataset_id=dataset.id\n",
        "    )\n",
        "\n",
        "print(f\"🚀 Added {len(runs)} runs to dataset {dataset.name!r}\")\n",
        "print(f\"🔗 View your dataset: {dataset.url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## 📊 LangSmith Run Summaries"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>name</th>\n",
              "      <th>method</th>\n",
              "      <th>status</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>prompt_cost</th>\n",
              "      <th>completion_cost</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>error</th>\n",
              "      <th>wrapper_error</th>\n",
              "      <th>response</th>\n",
              "      <th>context_docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>669f8f77-9fd8-4e5a-a72b-8b59297570af</td>\n",
              "      <td>semantic_retrieval</td>\n",
              "      <td>semantic</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:58.224322</td>\n",
              "      <td>2025-05-24 08:28:00.744770</td>\n",
              "      <td>2520.448</td>\n",
              "      <td>3049</td>\n",
              "      <td>179</td>\n",
              "      <td>3228</td>\n",
              "      <td>0.0012196</td>\n",
              "      <td>0.0002864</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The fir...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1a50dc51-bfc0-4673-8f4d-bac7f6e7e7aa</td>\n",
              "      <td>ensemble_retrieval</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:50.815286</td>\n",
              "      <td>2025-05-24 08:27:58.222934</td>\n",
              "      <td>7407.648</td>\n",
              "      <td>5977</td>\n",
              "      <td>283</td>\n",
              "      <td>6260</td>\n",
              "      <td>0.0023908</td>\n",
              "      <td>0.0004528</td>\n",
              "      <td>0.0028436</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided context, people generall...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3dd0525f-8275-44d1-b65f-0c4c469d1f11</td>\n",
              "      <td>parent_document_retrieval</td>\n",
              "      <td>parent_document</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:48.117814</td>\n",
              "      <td>2025-05-24 08:27:50.814115</td>\n",
              "      <td>2696.301</td>\n",
              "      <td>763</td>\n",
              "      <td>125</td>\n",
              "      <td>888</td>\n",
              "      <td>0.0003052</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0005052</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided context, people generall...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8155bfd0-638a-442e-bb5c-aa84c495a736</td>\n",
              "      <td>multi_query_retrieval</td>\n",
              "      <td>multi_query</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:38.911801</td>\n",
              "      <td>2025-05-24 08:27:48.115636</td>\n",
              "      <td>9203.835</td>\n",
              "      <td>5277</td>\n",
              "      <td>375</td>\n",
              "      <td>5652</td>\n",
              "      <td>0.0021108</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0027108</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided reviews and ratings, peo...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7df0a0b9-ba8f-48b5-b781-9112f217a4b3</td>\n",
              "      <td>contextual_compression</td>\n",
              "      <td>compression</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:36.480180</td>\n",
              "      <td>2025-05-24 08:27:38.911420</td>\n",
              "      <td>2431.240</td>\n",
              "      <td>1530</td>\n",
              "      <td>84</td>\n",
              "      <td>1614</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>0.0001344</td>\n",
              "      <td>0.0007464</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. Reviews...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3295ef13-8f04-432d-8bb4-d1fb453789e7</td>\n",
              "      <td>bm25_retrieval</td>\n",
              "      <td>bm25</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:34.308511</td>\n",
              "      <td>2025-05-24 08:27:36.479561</td>\n",
              "      <td>2171.050</td>\n",
              "      <td>1264</td>\n",
              "      <td>99</td>\n",
              "      <td>1363</td>\n",
              "      <td>0.0005056</td>\n",
              "      <td>0.0001584</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>People generally liked the first John Wick mov...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d8fab973-04b3-4f2f-91f2-25813f51d215</td>\n",
              "      <td>naive_retrieval</td>\n",
              "      <td>naive</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-24 08:27:31.612182</td>\n",
              "      <td>2025-05-24 08:27:34.308149</td>\n",
              "      <td>2695.967</td>\n",
              "      <td>3660</td>\n",
              "      <td>98</td>\n",
              "      <td>3758</td>\n",
              "      <td>0.001464</td>\n",
              "      <td>0.0001568</td>\n",
              "      <td>0.0016208</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked \"John Wick.\" The r...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 run_id                       name  \\\n",
              "0  669f8f77-9fd8-4e5a-a72b-8b59297570af         semantic_retrieval   \n",
              "1  1a50dc51-bfc0-4673-8f4d-bac7f6e7e7aa         ensemble_retrieval   \n",
              "2  3dd0525f-8275-44d1-b65f-0c4c469d1f11  parent_document_retrieval   \n",
              "3  8155bfd0-638a-442e-bb5c-aa84c495a736      multi_query_retrieval   \n",
              "4  7df0a0b9-ba8f-48b5-b781-9112f217a4b3     contextual_compression   \n",
              "5  3295ef13-8f04-432d-8bb4-d1fb453789e7             bm25_retrieval   \n",
              "6  d8fab973-04b3-4f2f-91f2-25813f51d215            naive_retrieval   \n",
              "\n",
              "            method   status                 start_time  \\\n",
              "0         semantic  success 2025-05-24 08:27:58.224322   \n",
              "1         ensemble  success 2025-05-24 08:27:50.815286   \n",
              "2  parent_document  success 2025-05-24 08:27:48.117814   \n",
              "3      multi_query  success 2025-05-24 08:27:38.911801   \n",
              "4      compression  success 2025-05-24 08:27:36.480180   \n",
              "5             bm25  success 2025-05-24 08:27:34.308511   \n",
              "6            naive  success 2025-05-24 08:27:31.612182   \n",
              "\n",
              "                    end_time  duration_ms  prompt_tokens  completion_tokens  \\\n",
              "0 2025-05-24 08:28:00.744770     2520.448           3049                179   \n",
              "1 2025-05-24 08:27:58.222934     7407.648           5977                283   \n",
              "2 2025-05-24 08:27:50.814115     2696.301            763                125   \n",
              "3 2025-05-24 08:27:48.115636     9203.835           5277                375   \n",
              "4 2025-05-24 08:27:38.911420     2431.240           1530                 84   \n",
              "5 2025-05-24 08:27:36.479561     2171.050           1264                 99   \n",
              "6 2025-05-24 08:27:34.308149     2695.967           3660                 98   \n",
              "\n",
              "   total_tokens prompt_cost completion_cost total_cost error wrapper_error  \\\n",
              "0          3228   0.0012196       0.0002864   0.001506  None          None   \n",
              "1          6260   0.0023908       0.0004528  0.0028436  None          None   \n",
              "2           888   0.0003052          0.0002  0.0005052  None          None   \n",
              "3          5652   0.0021108          0.0006  0.0027108  None          None   \n",
              "4          1614    0.000612       0.0001344  0.0007464  None          None   \n",
              "5          1363   0.0005056       0.0001584   0.000664  None          None   \n",
              "6          3758    0.001464       0.0001568  0.0016208  None          None   \n",
              "\n",
              "                                            response  context_docs  \n",
              "0  Yes, people generally liked John Wick. The fir...            10  \n",
              "1  Based on the provided context, people generall...            18  \n",
              "2  Based on the provided context, people generall...             3  \n",
              "3  Based on the provided reviews and ratings, peo...            16  \n",
              "4  Yes, people generally liked John Wick. Reviews...             3  \n",
              "5  People generally liked the first John Wick mov...             4  \n",
              "6  Yes, people generally liked \"John Wick.\" The r...            10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## 1️⃣ Build & Display Runs DataFrame\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import timezone, datetime, timedelta\n",
        "\n",
        "# Fetch all top-level chain runs for our project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "    start_time=datetime.now(timezone.utc) - timedelta(hours=1)  # last hour\n",
        "))\n",
        "\n",
        "# Build a record per run, pulling in every field “as is”\n",
        "records = []\n",
        "for run in runs:\n",
        "    records.append({\n",
        "        \"run_id\":          str(run.id),\n",
        "        \"name\":             run.name,\n",
        "        \"method\":           run.metadata.get(\"method\"),\n",
        "        \"status\":           run.status,\n",
        "        \"start_time\":       run.start_time,\n",
        "        \"end_time\":         run.end_time,\n",
        "        \"duration_ms\":      ((run.end_time - run.start_time).total_seconds()*1000)\n",
        "                              if run.start_time and run.end_time else None,\n",
        "        # cost & tokens\n",
        "        \"prompt_tokens\":    run.prompt_tokens,\n",
        "        \"completion_tokens\":run.completion_tokens,\n",
        "        \"total_tokens\":     run.total_tokens,\n",
        "        \"prompt_cost\":      run.prompt_cost,\n",
        "        \"completion_cost\":  run.completion_cost,\n",
        "        \"total_cost\":       run.total_cost,\n",
        "        # errors\n",
        "        \"error\":            run.error,                                   \n",
        "        \"wrapper_error\":    (run.outputs or {}).get(\"error\"),\n",
        "        # wrapper outputs\n",
        "        \"response\":         (run.outputs or {}).get(\"response\"),\n",
        "        \"context_docs\":     (run.outputs or {}).get(\"context_docs\"),\n",
        "    })\n",
        "\n",
        "df_runs = pd.DataFrame.from_records(records)\n",
        "\n",
        "display(Markdown(\"## 📊 LangSmith Run Summaries\"))\n",
        "display(df_runs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created dataset 'retrieval-method-comparison-20250524_012506_runs_custom_ds'\n",
            "✅ Added 7 runs to dataset 'retrieval-method-comparison-20250524_012506_runs_custom_ds'\n",
            "🔗 Dataset URL: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/dc8f154b-0e67-4dc6-82d3-e7ed23616d3e\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## 2️⃣ Ingest Runs into a LangSmith Dataset\n",
        "\n",
        "# %%\n",
        "# 1) Create or load the dataset\n",
        "dataset_name = f\"{project_name}_runs_custom_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"capturing inputs, outputs, tokens, costs, duration, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"✅ Created dataset {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"ℹ️  Using existing dataset {dataset.name!r}\")\n",
        "\n",
        "# 2) Bulk‐ingest each run as an Example\n",
        "for _, row in df_runs.iterrows():\n",
        "    langsmith_client.create_example(\n",
        "        dataset_id=dataset.id,\n",
        "        inputs={\n",
        "            \"run_id\": row[\"run_id\"],\n",
        "            \"method\": row[\"method\"],\n",
        "        },\n",
        "        outputs={\n",
        "            # include whichever outputs you care about:\n",
        "            \"response\": row[\"response\"],\n",
        "            \"context_docs\": int(row[\"context_docs\"]),\n",
        "        },\n",
        "        metadata={\n",
        "            # include metrics & error info as metadata\n",
        "            \"status\": row[\"status\"],\n",
        "            \"duration_ms\": float(row[\"duration_ms\"]),\n",
        "            \"prompt_tokens\": int(row[\"prompt_tokens\"]),\n",
        "            \"completion_tokens\": int(row[\"completion_tokens\"]),\n",
        "            \"total_tokens\": int(row[\"total_tokens\"]),\n",
        "            \"prompt_cost\": float(row[\"prompt_cost\"]),\n",
        "            \"completion_cost\": float(row[\"completion_cost\"]),\n",
        "            \"total_cost\": float(row[\"total_cost\"]),\n",
        "            # optionally include error\n",
        "            **({\"error\": row[\"error\"]} if pd.notna(row.get(\"error\")) else {}),\n",
        "            **({\"wrapper_error\": row[\"wrapper_error\"]} if pd.notna(row.get(\"wrapper_error\")) else {}),\n",
        "        }\n",
        "    )\n",
        "print(f\"✅ Added {len(df_runs)} runs to dataset {dataset.name!r}\")\n",
        "print(\"🔗 Dataset URL:\", dataset.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYuh2V1vHY6N"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYbdWnVHct-",
        "outputId": "11cc0bc2-434d-4512-99ed-870b64c09357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['johnwick_baseline', 'johnwick_semantic', 'johnwick_parent', 'airbnb_pdf_rec_1000_200_images', 'mcp-anthropic-desktop', 'mcp-nsclc', 'ambrose_lake_covenant']\n"
          ]
        }
      ],
      "source": [
        "# display existing collections\n",
        "\n",
        "existing = [c.name for c in cloud_client.get_collections().collections]\n",
        "\n",
        "print(type(existing))\n",
        "print(existing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaFQTs_MzlG",
        "outputId": "7fb85947-3663-4a83-a89f-b06fcf89d772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== baseline ===\n",
            "Exists?       True\n",
            "Point count:  count=100\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== parent ===\n",
            "Exists?       True\n",
            "Point count:  count=4817\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== semantic ===\n",
            "Exists?       True\n",
            "Point count:  count=179\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# display vector store collection metadata\n",
        "\n",
        "stores = {\n",
        "    \"baseline\": baseline_vectorstore,\n",
        "    \"parent\":  parent_vectorstore,\n",
        "    \"semantic\": semantic_vectorstore,\n",
        "}\n",
        "\n",
        "for name, vs in stores.items():\n",
        "    client = vs.client\n",
        "    col    = vs.collection_name\n",
        "    print(f\"=== {name} ===\")\n",
        "    # 1) Existence check\n",
        "    print(\"Exists?      \", client.collection_exists(col))\n",
        "    # 2) Point count\n",
        "    print(\"Point count: \", client.count(collection_name=col))\n",
        "    # 3) Full collection info\n",
        "    desc   = client.get_collection(collection_name=col)\n",
        "    params = desc.config.params\n",
        "\n",
        "    # — Vector dims & metric\n",
        "    vec_field = params.vectors\n",
        "    if isinstance(vec_field, dict):\n",
        "        # multi-vector mode: pick the first VectorParams\n",
        "        vp = next(iter(vec_field.values()))\n",
        "    else:\n",
        "        # single-vector mode: vectors is itself a VectorParams\n",
        "        vp = vec_field\n",
        "    print(\"Dim / metric:\", vp.size, \"/\", vp.distance)\n",
        "\n",
        "    # — Shard count & replication factor live on params\n",
        "    print(\"Shards / repl:\", params.shard_number, \"/\", params.replication_factor)\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDXX48ENcaEY",
        "outputId": "3d78a55f-2fc1-49c8-aee1-ffc3ffbf91a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in store: 100\n",
            "Metadata fields present: ['Author', 'Movie_Title', 'Rating', 'Review_Date', 'Review_Title', 'Review_Url', 'last_accessed_at', 'row', 'source']\n",
            "Metadata field types:\n",
            " • Review_Date: types=['str'], sample='6 May 2015'\n",
            " • Rating: types=['int'], sample=8\n",
            " • Review_Url: types=['str'], sample='/review/rw3233896/?ref_=tt_urv'\n",
            " • Review_Title: types=['str'], sample=' Kinetic, concise, and stylish; John Wick kicks ass.\\n'\n",
            " • Movie_Title: types=['str'], sample='John Wick 1'\n",
            " • last_accessed_at: types=['datetime'], sample=datetime.datetime(2025, 5, 21, 1, 25, 7, 682135)\n",
            " • row: types=['int'], sample=0\n",
            " • Author: types=['str'], sample='lnvicta'\n",
            " • source: types=['str'], sample='john_wick_1.csv'\n",
            "Doc 1 (ID=1428cd20-5729-4101-a425-3e822aeff0e2): 599 characters\n",
            "Doc 2 (ID=dbcd9e5e-f981-4f80-86ea-455ec001016e): 369 characters\n",
            "Doc 3 (ID=5c2047df-757b-423b-8bfb-379fd2e23644): 256 characters\n",
            "Doc 4 (ID=d0ad9d8e-301b-424e-b67c-9b03f96f326f): 426 characters\n",
            "Doc 5 (ID=8cc0e8c2-9254-4580-ab98-1c5a27db6a43): 902 characters\n"
          ]
        }
      ],
      "source": [
        "# Assume `store` already has docs via ParentDocumentRetriever\n",
        "#  (i.e. you already did retriever.add_documents(...) or similar)\n",
        "\n",
        "# 1) List all stored keys (document IDs)\n",
        "all_keys = list(store.yield_keys())\n",
        "print(f\"Total documents in store: {len(all_keys)}\")\n",
        "# print(\"Document IDs:\", all_keys)\n",
        "\n",
        "# 2) Fetch all Document objects\n",
        "docs = store.mget(all_keys)\n",
        "\n",
        "# 3) Examine metadata schema\n",
        "#    Collect all metadata field names across docs\n",
        "all_fields = set()\n",
        "for doc in docs:\n",
        "    all_fields.update(doc.metadata.keys())\n",
        "\n",
        "print(f\"Metadata fields present: {sorted(all_fields)}\")\n",
        "\n",
        "# 4) Show per-field value types and a sample value\n",
        "field_types = {field: set() for field in all_fields}\n",
        "for doc in docs:\n",
        "    for field, val in doc.metadata.items():\n",
        "        field_types[field].add(type(val).__name__)\n",
        "\n",
        "print(\"Metadata field types:\")\n",
        "for field, types in field_types.items():\n",
        "    sample = next((d.metadata[field] for d in docs if field in d.metadata), None)\n",
        "    print(f\" • {field}: types={sorted(types)}, sample={sample!r}\")\n",
        "\n",
        "# 5) (Optional) Print out first N docs’ text lengths to gauge “dimensions”\n",
        "for i, doc in enumerate(docs[:5], 1):\n",
        "    text_len = len(doc.page_content)\n",
        "    print(f\"Doc {i} (ID={all_keys[i-1]}): {text_len} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCKwiiOuHi9p"
      },
      "source": [
        "### Delete qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Pe_COpbsHcB7"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# initialize client (cloud or on-prem)\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        ")\n",
        "\n",
        "# create conditional deletion flag\n",
        "delete_collection = False\n",
        "\n",
        "if delete_collection:\n",
        "    # list of collections to drop\n",
        "    collections_to_reset = [\n",
        "        \"johnwick_baseline\",\n",
        "        \"johnwick_parent\",\n",
        "        \"johnwick_semantic\",\n",
        "    ]\n",
        "\n",
        "    for col_name in collections_to_reset:\n",
        "        # guard against missing collections\n",
        "        if cloud_client.collection_exists(col_name):\n",
        "            cloud_client.delete_collection(\n",
        "                collection_name=col_name,\n",
        "                timeout=60,  # seconds\n",
        "            )\n",
        "            print(f\"Deleted collection: {col_name}\")\n",
        "        else:\n",
        "            print(f\"Collection not found (skipped): {col_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KWMPESVcFT_"
      },
      "source": [
        "### Response Object validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHCFk-PajS6t",
        "outputId": "e77ca077-2d16-41d5-d5dc-fb5036f20e65"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked \"John Wick.\" The reviews highlight the film's slick action sequences, Keanu Reeves' strong performance, stylish choreography, and unique take on the revenge thriller genre. Many reviewers praised it as one of the best action films in recent years, noting its intense and well-crafted fight scenes, engaging pace, and well-developed world. While a few found it somewhat generic, the majority regarded it as a highly entertaining and fresh action movie that set new standards for the genre.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "People generally liked the first John Wick movie, as it received high praise for its stylish, kinetic action and unique criminal underworld, with ratings of 8 and 10 noted in the reviews. However, opinions seem mixed or negative for the later films, especially John Wick 3 and John Wick 4, which were criticized for lacking plot and being overly violent or weak compared to the original. Overall, the first film was well-liked, but the sequels received more divided or negative reception.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. Reviews highlight Keanu Reeves' slick performance, brilliant and well-choreographed action sequences, and the film’s stylish and intense depiction of a criminal underworld. It was praised as one of the best action films in recent years and recommended especially for action fans. However, some later reviews indicate that the magic felt strongest in the first film. Overall, the reception was very positive.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided reviews and ratings, people generally liked the John Wick films, especially the first two installments and John Wick 4, though opinions vary somewhat across the series.\n",
            "\n",
            "- The first John Wick movie received very positive feedback, with multiple reviews praising Keanu Reeves' performance, slick action sequences, stylish choreography, and a compelling revenge storyline centered around his dog's murder. Ratings like 9, 10, 8 are common, and reviewers called it \"the coolest action film you'll see all year,\" \"smoothest action film in a long time,\" and \"something special.\" Some saw it as a must-watch for action fans.\n",
            "\n",
            "- John Wick 2 was also well-received by many, with ratings around 8 and positive comments about its fast-paced story and high-quality action, though some felt it didn't surprise them as much as the first film.\n",
            "\n",
            "- The third film received more mixed reviews, with some fans enjoying the choreography but others feeling the magic was fading, noting issues with the plot and world-building. Ratings ranged from 0 to 6, indicating a divided reception.\n",
            "\n",
            "- John Wick 4 had some very positive reviews praising its intensity, set pieces, and consistency within the franchise, with ratings like 9. However, it also had some harsh criticism and lower ratings (e.g., a 1 and a 3), where reviewers described it as nonsensical, boring, or overly long.\n",
            "\n",
            "In summary, the John Wick series is generally liked, particularly the original film and the sequels to an extent, but there is some declining enthusiasm and mixed opinions in later installments. Overall, it is well-regarded in the action genre and has a strong fan base.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided context, people generally liked the John Wick series. For example, one review describes the first John Wick movie as highly recommended, praising its action and emotional setup. Another review mentions that the series has remained remarkably consistent and well received, with the reviewer considering \"John Wick: Chapter 4\" the best in the series.\n",
            "\n",
            "However, there are some negative opinions as well, such as a review of \"John Wick 4\" that calls it horrible and criticizes the plot and fight scenes.\n",
            "\n",
            "Overall, while there are mixed opinions, the general sentiment from the reviews suggests that many people do like John Wick.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided context, people generally liked the first John Wick movie. Multiple reviews praise its action sequences, Keanu Reeves's performance, stylish direction, and unique world-building. For example:\n",
            "\n",
            "- One reviewer gave it a 10/10, calling it \"something special\" with \"smooth\" action sequences and a cool criminal underworld.\n",
            "- Another rated it 9/10 and described it as the best action film of the year and one of the best in the past decade, highlighting the brutal but fun nature and Keanu Reeves's charisma.\n",
            "- Several others rated it 8 or higher, emphasizing its kinetic action, stylish choreography, and fresh take on revenge thrillers.\n",
            "- Although there are some moderate or mixed opinions (ratings around 5 or 6) that found it generic or simple, the overall tone is very positive.\n",
            "\n",
            "In contrast, some later installments in the series received more mixed or negative reactions, but the question specifically targets \"John Wick\" (generally understood as the first film), where the majority of evidence indicates it was well-liked by audiences and critics alike.\n",
            "\n",
            "**Summary:** Yes, people generally liked John Wick (the first movie), appreciating its stylish, fast-paced action and Keanu Reeves's performance.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The first film received very positive reviews praising its stylish action sequences, Keanu Reeves' performance, and its unique take on the action genre. Ratings for the first John Wick movie include 9/10 and 8/10, with reviewers calling it \"the coolest action film you'll see all year,\" \"slick, violent fun,\" and \"the best action film of the year.\" \n",
            "\n",
            "While the third installment had some mixed reviews, with one review giving it a 5/10 and mentioning that \"the magic is gone,\" the overall franchise remains well-received. The fourth film was also praised highly, with ratings of 9/10 and comments on its consistency and quality even after multiple sequels.\n",
            "\n",
            "In summary, the John Wick series has been generally well-liked, especially the first film, and has maintained a strong fanbase throughout its sequels.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to response objects\n",
        "responses = {\n",
        "    \"Naive Retrieval Chain Response\":              naive_retrieval_chain_response,\n",
        "    \"BM25 Retrieval Chain Response\":               bm25_retrieval_chain_response,\n",
        "    \"Contextual Compression Chain Response\":       contextual_compression_retrieval_chain_response,\n",
        "    \"Multi-Query Retrieval Chain Response\":        multi_query_retrieval_chain_response,\n",
        "    \"Parent Document Retrieval Chain Response\":    parent_document_retrieval_chain_response,\n",
        "    \"Ensemble Retrieval Chain Response\":           ensemble_retrieval_chain_response,\n",
        "    \"Semantic Retrieval Chain Response\":           semantic_retrieval_chain_response,\n",
        "}\n",
        "\n",
        "for header, resp in responses.items():\n",
        "    display(Markdown(f\"## {header}\\n\"))\n",
        "    print(\"\\n\")\n",
        "    print(resp)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGRzkNHjPUd"
      },
      "source": [
        "### Retrieval Chain visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vZOd4DL9NS3k",
        "outputId": "860d77fb-83d0-4ec7-a8d3-27cb66d8ae60"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f34c4b93890>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f34c4b4c050>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10})),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser()),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f3504443e10>, docstore=<langchain_core.stores.InMemoryStore object at 0x7f350d231050>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f3504443e50>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7f34c4b93890>), VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10}), ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f3504443e10>, docstore=<langchain_core.stores.InMemoryStore object at 0x7f350d231050>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7f3504443e50>), ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7f34c4b4c050>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10})), MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f350d1aacd0>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser())], weights=[0.2, 0.2, 0.2, 0.2, 0.2]),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7f34c4bc2f90>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f354364fc10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f3543086010>, root_client=<openai.OpenAI object at 0x7f3559673450>, root_async_client=<openai.AsyncOpenAI object at 0x7f35431866d0>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to chains\n",
        "chains = {\n",
        "    \"Naive Retrieval\":              naive_retrieval_chain,\n",
        "    \"BM25 Retrieval\":               bm25_retrieval_chain,\n",
        "    \"Contextual Compression\":       contextual_compression_retrieval_chain,\n",
        "    \"Multi-Query Retrieval\":        multi_query_retrieval_chain,\n",
        "    \"Parent Document Retrieval\":    parent_document_retrieval_chain,\n",
        "    \"Ensemble Retrieval\":           ensemble_retrieval_chain,\n",
        "    \"Semantic Retrieval\":           semantic_retrieval_chain,\n",
        "}\n",
        "\n",
        "for title, chain in chains.items():\n",
        "    display(Markdown(f\"## {title}\\n\"))\n",
        "    print(chain)\n",
        "    # print(chain.get_graph().draw_ascii())\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
