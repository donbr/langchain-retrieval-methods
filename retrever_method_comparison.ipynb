{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Welcome to the **LangChain Retrieval Methods** notebook.  \n",
        "In this tutorial you will:\n",
        "\n",
        "1. **Load** a small corpus of John Wick movie reviews.\n",
        "2. **Explore** seven distinct retrieval strategies:\n",
        "   - Naive (whole‚Äêdocument vectors)\n",
        "   - BM25 (keyword matching)\n",
        "   - Contextual Compression (reranking)\n",
        "   - Multi‚ÄêQuery (query expansion)\n",
        "   - Parent Document (hierarchical chunks)\n",
        "   - Ensemble (fusion of methods)\n",
        "   - Semantic (boundary‚Äêaware chunking)\n",
        "\n",
        "3. **Compare** each method across:\n",
        "   - Retrieval **quality** (recall, qualitative response patterns)\n",
        "   - **Latency** (ms per query)\n",
        "   - **Cost** (API/token usage)\n",
        "   - **Resource footprint** (index size & shape)\n",
        "\n",
        "4. **Visualize** key metrics and response examples to understand trade-offs.\n",
        "\n",
        "By the end of the notebook, you‚Äôll know:\n",
        "- When to **start simple** (Naive or BM25) versus **scale up** (Ensemble or Semantic).\n",
        "- How context-window advances (4 K ‚Üí 32 K ‚Üí 128 K) and loader-splitter decoupling shape modern RAG architectures.\n",
        "- Practical tips for **production readiness**, including index sharding, zero-downtime reindexes, and drift monitoring.\n",
        "\n",
        "> **Prerequisites**  \n",
        "> - Python 3.11 environment (see Quickstart)  \n",
        "> - Access to a Qdrant Cloud instance (with API key)  \n",
        "> - OpenAI API credentials for embedding & reranking  \n",
        "\n",
        "Run the cells in order, or jump to the section that interests you. Let‚Äôs get started!  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚òï üì¥ üî• TLDR ‚òï üì¥ üî•\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| ‚òï Morning Coffee Startup | `docker compose up -d` |\n",
        "| üì¥ That's a Wrap | `docker compose down` |\n",
        "| üî• Burn It All Down | `docker compose down --volumes --rmi all` |\n",
        "\n",
        "Read the more [detailed version here](#foundation-docker-containers-for-qdrant--redis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Environment Configuration & API Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Build a dynamic project name (e.g. include timestamp)\n",
        "project_name = f\"retrieval-method-comparison-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"COHERE_API_KEY\"] = os.getenv('COHERE_API_KEY')\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = project_name\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv('LANGSMITH_API_KEY')\n",
        "\n",
        "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "QDRANT_API_URL = os.getenv(\"QDRANT_API_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "## üìä Dataset Loading & Preprocessing for RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "d794aa3a-234c-4fe7-b219-02e8b36c27ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "john_wick_1.csv already exists.\n",
            "john_wick_2.csv already exists.\n",
            "john_wick_3.csv already exists.\n",
            "john_wick_4.csv already exists.\n"
          ]
        }
      ],
      "source": [
        "# Set up a consistent data directory in the user's home directory\n",
        "from pathlib import Path\n",
        "DATA_DIR = Path.cwd() / \"data\"\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# URLs and filenames\n",
        "urls = [\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\", \"john_wick_1.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\", \"john_wick_2.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\", \"john_wick_3.csv\"),\n",
        "    (\"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\", \"john_wick_4.csv\"),\n",
        "]\n",
        "\n",
        "# Download files if not already present\n",
        "for url, fname in urls:\n",
        "    file_path = DATA_DIR / fname\n",
        "    if not file_path.exists():\n",
        "        print(f\"Downloading {fname}...\")\n",
        "        r = requests.get(url)\n",
        "        r.raise_for_status()\n",
        "        file_path.write_bytes(r.content)\n",
        "    else:\n",
        "        print(f\"{fname} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "all_review_docs = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "    loader = CSVLoader(\n",
        "        file_path=(DATA_DIR / f\"john_wick_{i}.csv\"),\n",
        "        metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "    )\n",
        "\n",
        "    movie_docs = loader.load()\n",
        "    for doc in movie_docs:\n",
        "\n",
        "        # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "        doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "        # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "        doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "        # newer movies have a more recent \"last_accessed_at\" (store as ISO string)\n",
        "        doc.metadata[\"last_accessed_at\"] = (datetime.now() - timedelta(days=4-i)).isoformat()\n",
        "\n",
        "    all_review_docs.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## üèóÔ∏è Building RAG Infrastructure: Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AX5XBOIltcvD"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore  # Updated import\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain_community.storage import RedisStore\n",
        "from langchain.storage import create_kv_docstore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Foundation: Docker Containers for Qdrant & Redis\n",
        "\n",
        "- use Docker Compose to setup containers\n",
        "- [the `docker-compose.yml file is located here](docker-compose.yml)\n",
        "\n",
        "| Action | Command |\n",
        "|---|---|\n",
        "| Start containers | `docker compose up -d` |\n",
        "| Stop containers | `docker compose down` |\n",
        "| Stop containers - remove volumes, images | `docker compose down --volumes --rmi all` |\n",
        "\n",
        "- the last option is great for resets and starting from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 1: Simple Vector Storage (Baseline)\n",
        "\n",
        "- creates the vector store using the all_review_docs Document object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6Hta5PoJlos"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/donbr/aim/langchain-retrieval-methods/.venv/lib/python3.11/site-packages/langchain_qdrant/qdrant.py:808: UserWarning: Api key is used with an insecure connection.\n",
            "  client = QdrantClient(**client_options)\n"
          ]
        }
      ],
      "source": [
        "baseline_vectorstore = QdrantVectorStore.from_documents(\n",
        "    all_review_docs,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_baseline\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 2: Hierarchical Storage (Parent-Child Architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Documents: Redis Key-Value Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CjIJlsjsrOSi"
      },
      "outputs": [],
      "source": [
        "redis_byte_store = RedisStore(redis_url=\"redis://localhost:6379\")\n",
        "parent_document_store = create_kv_docstore(redis_byte_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Child Records: Qdrant Vector Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_39335/1364238518.py:2: UserWarning: Api key is used with an insecure connection.\n",
            "  cloud_client = QdrantClient(\n"
          ]
        }
      ],
      "source": [
        "# Initialize Qdrant client\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True\n",
        ")\n",
        "\n",
        "# Check if the Qdrant collection exists\n",
        "if not cloud_client.collection_exists(\"johnwick_parent_children\"):\n",
        "    cloud_client.create_collection(\n",
        "        collection_name=\"johnwick_parent_children\",\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=1536,\n",
        "            distance=models.Distance.COSINE\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Construct the VectorStore using cloud client\n",
        "parent_children_vectorstore = QdrantVectorStore(\n",
        "    embedding=embeddings,\n",
        "    client=cloud_client,\n",
        "    collection_name=\"johnwick_parent_children\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retriever definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_children_vectorstore,\n",
        "    docstore=parent_document_store,\n",
        "    child_splitter=child_splitter,\n",
        ")\n",
        "\n",
        "parent_document_retriever.add_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Level 3: Vector Storage organized by Semantic Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RmMfpBIcF3dN"
      },
      "outputs": [],
      "source": [
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")\n",
        "\n",
        "semantic_documents = semantic_chunker.split_documents(all_review_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_vectorstore = QdrantVectorStore.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        "    collection_name=\"johnwick_semantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaIgKvJmpjFu"
      },
      "source": [
        "## üéØ Core Learning: 7 Retrieval Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strategy Setup: Tracing & Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup langsmith tracing\n",
        "\n",
        "from langsmith import Client, traceable\n",
        "\n",
        "langsmith_client = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "### Strategy 1: Naive Retrieval (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retriever = baseline_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "### Strategy 2: BM25 Retrieval (Keyword-Based)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(all_review_docs)\n",
        "\n",
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "### Strategy 3: Contextual Compression (AI Reranking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "### Strategy 4: Multi-Query Retrieval (Query Expansion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever,\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "### Strategy 5: Parent Document Retrieval (Hierarchical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "### Strategy 6: Ensemble Retrieval (Combined Methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list,\n",
        "    weights=equal_weighting\n",
        ")\n",
        "\n",
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "### Strategy 7: Semantic Retrieval (Semantic Chunking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})\n",
        "\n",
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Performance Monitoring & Evaluation Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Traceable wrappers defined\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable(name=\"naive_retrieval\", run_type=\"chain\", metadata={\"method\":\"naive\"})\n",
        "def trace_naive_retrieval(question: str):\n",
        "    try:\n",
        "        result = naive_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"bm25_retrieval\", run_type=\"chain\", metadata={\"method\":\"bm25\"})\n",
        "def trace_bm25_retrieval(question: str):\n",
        "    try:\n",
        "        # Use the correct chain variable name here\n",
        "        res = bm25_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": res[\"response\"].content,\n",
        "            \"context_docs\": len(res[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"contextual_compression\", run_type=\"chain\", metadata={\"method\":\"compression\"})\n",
        "def trace_contextual_compression(question: str):\n",
        "    try:\n",
        "        result = contextual_compression_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"multi_query_retrieval\", run_type=\"chain\", metadata={\"method\":\"multi_query\"})\n",
        "def trace_multi_query_retrieval(question: str):\n",
        "    try:\n",
        "        result = multi_query_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"parent_document_retrieval\", run_type=\"chain\", metadata={\"method\":\"parent_document\"})\n",
        "def trace_parent_document_retrieval(question: str):\n",
        "    try:\n",
        "        result = parent_document_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"ensemble_retrieval\", run_type=\"chain\", metadata={\"method\":\"ensemble\"})\n",
        "def trace_ensemble_retrieval(question: str):\n",
        "    try:\n",
        "        result = ensemble_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "@traceable(name=\"semantic_retrieval\", run_type=\"chain\", metadata={\"method\":\"semantic\"})\n",
        "def trace_semantic_retrieval(question: str):\n",
        "    try:\n",
        "        result = semantic_retrieval_chain.invoke({\"question\": question})\n",
        "        return {\n",
        "            \"response\": result[\"response\"].content,\n",
        "            \"context_docs\": len(result[\"context\"])\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "print(\"‚úÖ Traceable wrappers defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Execution & Real-Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All methods executed with tracing\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "question = \"Did people generally like John Wick?\"\n",
        "\n",
        "naive_retrieval_chain_response = trace_naive_retrieval(question)[\"response\"]\n",
        "bm25_retrieval_chain_response = trace_bm25_retrieval(question)[\"response\"]\n",
        "contextual_compression_retrieval_chain_response = trace_contextual_compression(question)[\"response\"]\n",
        "multi_query_retrieval_chain_response = trace_multi_query_retrieval(question)[\"response\"]\n",
        "semantic_retrieval_chain_response = trace_semantic_retrieval(question)[\"response\"]\n",
        "\n",
        "print(\"‚úÖ All methods executed with tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent Document Retrieval traces\n",
        "\n",
        "- broke these two out due to some serialization issues after adopting Redis\n",
        "- helped with troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain_response = trace_parent_document_retrieval(question)[\"response\"]\n",
        "ensemble_retrieval_chain_response = trace_ensemble_retrieval(question)[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tracers.langchain import wait_for_all_tracers\n",
        "\n",
        "# run after all your traceable calls\n",
        "wait_for_all_tracers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Results Analysis & Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset: 'retrieval-method-comparison-20250526_174608_runs_ds'\n",
            "üöÄ Added 7 runs to dataset 'retrieval-method-comparison-20250526_174608_runs_ds'\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "# Assume langsmith_client is already initialized,\n",
        "# and `project_name` is set as above.\n",
        "\n",
        "# 1. Ensure the dataset exists or create it\n",
        "dataset_name = f\"{project_name}_runs_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"including method, response, context_docs, tokens, costs, durations, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset: {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset: {dataset.name!r}\")\n",
        "\n",
        "# 2. Fetch all top-level chain runs for the project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "))\n",
        "\n",
        "# 3. Ingest each run as an Example in the dataset\n",
        "for run in runs:\n",
        "    langsmith_client.create_example_from_run(\n",
        "        run=run,\n",
        "        dataset_id=dataset.id\n",
        "    )\n",
        "\n",
        "print(f\"üöÄ Added {len(runs)} runs to dataset {dataset.name!r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View LangGraph Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó View your dataset: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/c24ab0e8-c9e1-445e-a57d-6bbf9901b006\n"
          ]
        }
      ],
      "source": [
        "print(f\"üîó View your dataset: {dataset.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import timezone, datetime, timedelta\n",
        "\n",
        "# Fetch all top-level chain runs for our project\n",
        "runs = list(langsmith_client.list_runs(\n",
        "    project_name=project_name,\n",
        "    is_root=True,\n",
        "    run_type=\"chain\",\n",
        "    start_time=datetime.now(timezone.utc) - timedelta(hours=1)  # last hour\n",
        "))\n",
        "\n",
        "# Build a record per run, pulling in every field ‚Äúas is‚Äù\n",
        "records = []\n",
        "for run in runs:\n",
        "    records.append({\n",
        "        \"run_id\":          str(run.id),\n",
        "        \"name\":             run.name,\n",
        "        \"method\":           run.metadata.get(\"method\"),\n",
        "        \"status\":           run.status,\n",
        "        \"start_time\":       run.start_time,\n",
        "        \"end_time\":         run.end_time,\n",
        "        \"duration_ms\":      ((run.end_time - run.start_time).total_seconds()*1000)\n",
        "                              if run.start_time and run.end_time else None,\n",
        "        # cost & tokens\n",
        "        \"prompt_tokens\":    run.prompt_tokens,\n",
        "        \"completion_tokens\":run.completion_tokens,\n",
        "        \"total_tokens\":     run.total_tokens,\n",
        "        \"prompt_cost\":      run.prompt_cost,\n",
        "        \"completion_cost\":  run.completion_cost,\n",
        "        \"total_cost\":       run.total_cost,\n",
        "        # errors\n",
        "        \"error\":            run.error,                                   \n",
        "        \"wrapper_error\":    (run.outputs or {}).get(\"error\"),\n",
        "        # wrapper outputs\n",
        "        \"response\":         (run.outputs or {}).get(\"response\"),\n",
        "        \"context_docs\":     (run.outputs or {}).get(\"context_docs\"),\n",
        "    })\n",
        "\n",
        "df_runs = pd.DataFrame.from_records(records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Retrieval Strategy Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>name</th>\n",
              "      <th>method</th>\n",
              "      <th>status</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>prompt_tokens</th>\n",
              "      <th>completion_tokens</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>prompt_cost</th>\n",
              "      <th>completion_cost</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>error</th>\n",
              "      <th>wrapper_error</th>\n",
              "      <th>response</th>\n",
              "      <th>context_docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b0f93c2a-13a5-4245-b401-050d714979cc</td>\n",
              "      <td>ensemble_retrieval</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:56.304268</td>\n",
              "      <td>2025-05-27 00:48:04.060190</td>\n",
              "      <td>7755.922</td>\n",
              "      <td>6507</td>\n",
              "      <td>303</td>\n",
              "      <td>6810</td>\n",
              "      <td>0.0026028</td>\n",
              "      <td>0.0004848</td>\n",
              "      <td>0.0030876</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the reviews provided, people generall...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ccaa6913-b7a9-4de4-9231-b608b276ec62</td>\n",
              "      <td>parent_document_retrieval</td>\n",
              "      <td>parent_document</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:53.546881</td>\n",
              "      <td>2025-05-27 00:47:56.303416</td>\n",
              "      <td>2756.535</td>\n",
              "      <td>784</td>\n",
              "      <td>128</td>\n",
              "      <td>912</td>\n",
              "      <td>0.0003136</td>\n",
              "      <td>0.0002048</td>\n",
              "      <td>0.0005184</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Based on the provided reviews, people generall...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0a6d95d2-4b1e-4600-9721-68039921045e</td>\n",
              "      <td>semantic_retrieval</td>\n",
              "      <td>semantic</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:49.811785</td>\n",
              "      <td>2025-05-27 00:47:53.539907</td>\n",
              "      <td>3728.122</td>\n",
              "      <td>3185</td>\n",
              "      <td>178</td>\n",
              "      <td>3363</td>\n",
              "      <td>0.001274</td>\n",
              "      <td>0.0002848</td>\n",
              "      <td>0.0015588</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The fir...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35aba433-6cf7-4ef6-a4c2-75ed6a44300f</td>\n",
              "      <td>multi_query_retrieval</td>\n",
              "      <td>multi_query</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:45.008412</td>\n",
              "      <td>2025-05-27 00:47:49.810941</td>\n",
              "      <td>4802.529</td>\n",
              "      <td>5300</td>\n",
              "      <td>158</td>\n",
              "      <td>5458</td>\n",
              "      <td>0.00212</td>\n",
              "      <td>0.0002528</td>\n",
              "      <td>0.0023728</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked the movie *John Wi...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>289016ac-6d19-4b96-a020-2f14261633b6</td>\n",
              "      <td>contextual_compression</td>\n",
              "      <td>compression</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:41.963152</td>\n",
              "      <td>2025-05-27 00:47:45.007657</td>\n",
              "      <td>3044.505</td>\n",
              "      <td>1569</td>\n",
              "      <td>98</td>\n",
              "      <td>1667</td>\n",
              "      <td>0.0006276</td>\n",
              "      <td>0.0001568</td>\n",
              "      <td>0.0007844</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. Reviews...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ca4f8bd5-06f1-4d50-9a49-44fc35f02ce6</td>\n",
              "      <td>bm25_retrieval</td>\n",
              "      <td>bm25</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:38.078126</td>\n",
              "      <td>2025-05-27 00:47:41.962353</td>\n",
              "      <td>3884.227</td>\n",
              "      <td>1292</td>\n",
              "      <td>229</td>\n",
              "      <td>1521</td>\n",
              "      <td>0.0005168</td>\n",
              "      <td>0.0003664</td>\n",
              "      <td>0.0008832</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>People's opinions on John Wick vary based on t...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>31e6f3cd-c9a8-40bb-9c3b-c724721fb5e6</td>\n",
              "      <td>naive_retrieval</td>\n",
              "      <td>naive</td>\n",
              "      <td>success</td>\n",
              "      <td>2025-05-27 00:47:35.153144</td>\n",
              "      <td>2025-05-27 00:47:38.077668</td>\n",
              "      <td>2924.524</td>\n",
              "      <td>3800</td>\n",
              "      <td>95</td>\n",
              "      <td>3895</td>\n",
              "      <td>0.00152</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.001672</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Yes, people generally liked John Wick. The rev...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 run_id                       name  \\\n",
              "0  b0f93c2a-13a5-4245-b401-050d714979cc         ensemble_retrieval   \n",
              "1  ccaa6913-b7a9-4de4-9231-b608b276ec62  parent_document_retrieval   \n",
              "2  0a6d95d2-4b1e-4600-9721-68039921045e         semantic_retrieval   \n",
              "3  35aba433-6cf7-4ef6-a4c2-75ed6a44300f      multi_query_retrieval   \n",
              "4  289016ac-6d19-4b96-a020-2f14261633b6     contextual_compression   \n",
              "5  ca4f8bd5-06f1-4d50-9a49-44fc35f02ce6             bm25_retrieval   \n",
              "6  31e6f3cd-c9a8-40bb-9c3b-c724721fb5e6            naive_retrieval   \n",
              "\n",
              "            method   status                 start_time  \\\n",
              "0         ensemble  success 2025-05-27 00:47:56.304268   \n",
              "1  parent_document  success 2025-05-27 00:47:53.546881   \n",
              "2         semantic  success 2025-05-27 00:47:49.811785   \n",
              "3      multi_query  success 2025-05-27 00:47:45.008412   \n",
              "4      compression  success 2025-05-27 00:47:41.963152   \n",
              "5             bm25  success 2025-05-27 00:47:38.078126   \n",
              "6            naive  success 2025-05-27 00:47:35.153144   \n",
              "\n",
              "                    end_time  duration_ms  prompt_tokens  completion_tokens  \\\n",
              "0 2025-05-27 00:48:04.060190     7755.922           6507                303   \n",
              "1 2025-05-27 00:47:56.303416     2756.535            784                128   \n",
              "2 2025-05-27 00:47:53.539907     3728.122           3185                178   \n",
              "3 2025-05-27 00:47:49.810941     4802.529           5300                158   \n",
              "4 2025-05-27 00:47:45.007657     3044.505           1569                 98   \n",
              "5 2025-05-27 00:47:41.962353     3884.227           1292                229   \n",
              "6 2025-05-27 00:47:38.077668     2924.524           3800                 95   \n",
              "\n",
              "   total_tokens prompt_cost completion_cost total_cost error wrapper_error  \\\n",
              "0          6810   0.0026028       0.0004848  0.0030876  None          None   \n",
              "1           912   0.0003136       0.0002048  0.0005184  None          None   \n",
              "2          3363    0.001274       0.0002848  0.0015588  None          None   \n",
              "3          5458     0.00212       0.0002528  0.0023728  None          None   \n",
              "4          1667   0.0006276       0.0001568  0.0007844  None          None   \n",
              "5          1521   0.0005168       0.0003664  0.0008832  None          None   \n",
              "6          3895     0.00152        0.000152   0.001672  None          None   \n",
              "\n",
              "                                            response  context_docs  \n",
              "0  Based on the reviews provided, people generall...            20  \n",
              "1  Based on the provided reviews, people generall...             3  \n",
              "2  Yes, people generally liked John Wick. The fir...            10  \n",
              "3  Yes, people generally liked the movie *John Wi...            14  \n",
              "4  Yes, people generally liked John Wick. Reviews...             3  \n",
              "5  People's opinions on John Wick vary based on t...             4  \n",
              "6  Yes, people generally liked John Wick. The rev...            10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df_runs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upload Retrieval Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset 'retrieval-method-comparison-20250526_174608_runs_custom_ds'\n",
            "‚úÖ Added 7 runs to dataset 'retrieval-method-comparison-20250526_174608_runs_custom_ds'\n",
            "üîó Dataset URL: https://smith.langchain.com/o/2ad170d9-2e91-430d-9d70-cf6501e2184c/datasets/471fd817-a682-454d-b2b3-abee9583cf49\n"
          ]
        }
      ],
      "source": [
        "# 1) Create or load the dataset\n",
        "dataset_name = f\"{project_name}_runs_custom_ds\"\n",
        "try:\n",
        "    dataset = langsmith_client.create_dataset(\n",
        "        dataset_name=dataset_name,\n",
        "        description=(\n",
        "            \"All root chain runs from the John Wick retrieval-method notebook, \"\n",
        "            \"capturing inputs, outputs, tokens, costs, duration, and errors.\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"‚úÖ Created dataset {dataset.name!r}\")\n",
        "except Exception:\n",
        "    dataset = langsmith_client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"‚ÑπÔ∏è  Using existing dataset {dataset.name!r}\")\n",
        "\n",
        "# 2) Bulk‚Äêingest each run as an Example\n",
        "for _, row in df_runs.iterrows():\n",
        "    langsmith_client.create_example(\n",
        "        dataset_id=dataset.id,\n",
        "        inputs={\n",
        "            \"run_id\": row[\"run_id\"],\n",
        "            \"method\": row[\"method\"],\n",
        "        },\n",
        "        outputs={\n",
        "            # include whichever outputs you care about:\n",
        "            \"response\": row[\"response\"],\n",
        "            \"context_docs\": int(row[\"context_docs\"]),\n",
        "        },\n",
        "        metadata={\n",
        "            # include metrics & error info as metadata\n",
        "            \"status\": row[\"status\"],\n",
        "            \"duration_ms\": float(row[\"duration_ms\"]),\n",
        "            \"prompt_tokens\": int(row[\"prompt_tokens\"]),\n",
        "            \"completion_tokens\": int(row[\"completion_tokens\"]),\n",
        "            \"total_tokens\": int(row[\"total_tokens\"]),\n",
        "            \"prompt_cost\": float(row[\"prompt_cost\"]),\n",
        "            \"completion_cost\": float(row[\"completion_cost\"]),\n",
        "            \"total_cost\": float(row[\"total_cost\"]),\n",
        "            # optionally include error\n",
        "            **({\"error\": row[\"error\"]} if pd.notna(row.get(\"error\")) else {}),\n",
        "            **({\"wrapper_error\": row[\"wrapper_error\"]} if pd.notna(row.get(\"wrapper_error\")) else {}),\n",
        "        }\n",
        "    )\n",
        "print(f\"‚úÖ Added {len(df_runs)} runs to dataset {dataset.name!r}\")\n",
        "print(\"üîó Dataset URL:\", dataset.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYuh2V1vHY6N"
      },
      "source": [
        "## üõ†Ô∏è Exploration Tools & Cleanup Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List of Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwYbdWnVHct-",
        "outputId": "11cc0bc2-434d-4512-99ed-870b64c09357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "['johnwick_semantic', 'johnwick_parent_children', 'johnwick_baseline']\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant collections\n",
        "\n",
        "existing = [c.name for c in cloud_client.get_collections().collections]\n",
        "\n",
        "print(type(existing))\n",
        "print(existing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Qdrant info by Storage Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfaFQTs_MzlG",
        "outputId": "7fb85947-3663-4a83-a89f-b06fcf89d772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== baseline ===\n",
            "Exists?       True\n",
            "Point count:  count=100\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== parent ===\n",
            "Exists?       True\n",
            "Point count:  count=4817\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n",
            "=== semantic ===\n",
            "Exists?       True\n",
            "Point count:  count=179\n",
            "Dim / metric: 1536 / Cosine\n",
            "Shards / repl: 1 / 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# display Qdrant vector store collection metadata\n",
        "\n",
        "stores = {\n",
        "    \"baseline\": baseline_vectorstore,\n",
        "    \"parent\":  parent_children_vectorstore,\n",
        "    \"semantic\": semantic_vectorstore,\n",
        "}\n",
        "\n",
        "for name, vs in stores.items():\n",
        "    client = vs.client\n",
        "    col    = vs.collection_name\n",
        "    print(f\"=== {name} ===\")\n",
        "    # 1) Existence check\n",
        "    print(\"Exists?      \", client.collection_exists(col))\n",
        "    # 2) Point count\n",
        "    print(\"Point count: \", client.count(collection_name=col))\n",
        "    # 3) Full collection info\n",
        "    desc   = client.get_collection(collection_name=col)\n",
        "    params = desc.config.params\n",
        "\n",
        "    # ‚Äî Vector dims & metric\n",
        "    vec_field = params.vectors\n",
        "    if isinstance(vec_field, dict):\n",
        "        # multi-vector mode: pick the first VectorParams\n",
        "        vp = next(iter(vec_field.values()))\n",
        "    else:\n",
        "        # single-vector mode: vectors is itself a VectorParams\n",
        "        vp = vec_field\n",
        "    print(\"Dim / metric:\", vp.size, \"/\", vp.distance)\n",
        "\n",
        "    # ‚Äî Shard count & replication factor live on params\n",
        "    print(\"Shards / repl:\", params.shard_number, \"/\", params.replication_factor)\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Redis info for Parent Document Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDXX48ENcaEY",
        "outputId": "3d78a55f-2fc1-49c8-aee1-ffc3ffbf91a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in store: 100\n",
            "Metadata fields present: ['Author', 'Movie_Title', 'Rating', 'Review_Date', 'Review_Title', 'Review_Url', 'last_accessed_at', 'row', 'source']\n",
            "Metadata field types:\n",
            " ‚Ä¢ Review_Title: types=['str'], sample=' A New Franchise is Born\\n'\n",
            " ‚Ä¢ Review_Url: types=['str'], sample='/review/rw3718180/?ref_=tt_urv'\n",
            " ‚Ä¢ Author: types=['str'], sample='claudio_carvalho'\n",
            " ‚Ä¢ Review_Date: types=['str'], sample='28 May 2017'\n",
            " ‚Ä¢ source: types=['str'], sample='/home/donbr/aim/langchain-retrieval-methods/data/john_wick_2.csv'\n",
            " ‚Ä¢ last_accessed_at: types=['str'], sample='2025-05-24T17:46:09.911224'\n",
            " ‚Ä¢ Movie_Title: types=['str'], sample='John Wick 2'\n",
            " ‚Ä¢ Rating: types=['int'], sample=8\n",
            " ‚Ä¢ row: types=['int'], sample=20\n",
            "Doc 1 (ID=9d5afca1-0163-4c14-88dd-b14777deed5d): 850 characters\n",
            "Doc 2 (ID=d830af85-440e-43fe-aff6-def5258ea936): 732 characters\n",
            "Doc 3 (ID=95b6de49-3ea9-406d-8f50-8ad613b95425): 160 characters\n",
            "Doc 4 (ID=5575009b-4661-45f5-b89d-ad557e6ec583): 367 characters\n",
            "Doc 5 (ID=c27204a3-0046-4b37-ab50-d4945ec4cab4): 547 characters\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assume `parent_document_store` already has docs via ParentDocumentRetriever\n",
        "#  (i.e. you already did retriever.add_documents(...) or similar)\n",
        "\n",
        "# 1) List all stored keys (document IDs)\n",
        "all_keys = list(parent_document_store.yield_keys())\n",
        "print(f\"Total documents in store: {len(all_keys)}\")\n",
        "# print(\"Document IDs:\", all_keys)\n",
        "\n",
        "# 2) Fetch all Document objects\n",
        "docs = parent_document_store.mget(all_keys)\n",
        "\n",
        "# 3) Examine metadata schema\n",
        "#    Collect all metadata field names across docs\n",
        "all_fields = set()\n",
        "for doc in docs:\n",
        "    all_fields.update(doc.metadata.keys())\n",
        "\n",
        "print(f\"Metadata fields present: {sorted(all_fields)}\")\n",
        "\n",
        "# 4) Show per-field value types and a sample value\n",
        "field_types = {field: set() for field in all_fields}\n",
        "for doc in docs:\n",
        "    for field, val in doc.metadata.items():\n",
        "        field_types[field].add(type(val).__name__)\n",
        "\n",
        "print(\"Metadata field types:\")\n",
        "for field, types in field_types.items():\n",
        "    sample = next((d.metadata[field] for d in docs if field in d.metadata), None)\n",
        "    print(f\" ‚Ä¢ {field}: types={sorted(types)}, sample={sample!r}\")\n",
        "\n",
        "# 5) (Optional) Print out first N docs‚Äô text lengths to gauge ‚Äúdimensions‚Äù\n",
        "for i, doc in enumerate(docs[:5], 1):\n",
        "    text_len = len(doc.page_content)\n",
        "    print(f\"Doc {i} (ID={all_keys[i-1]}): {text_len} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCKwiiOuHi9p"
      },
      "source": [
        "### Delete Qdrant collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Pe_COpbsHcB7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_39335/3294298368.py:5: UserWarning: Api key is used with an insecure connection.\n",
            "  cloud_client = QdrantClient(\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# initialize client (cloud or on-prem)\n",
        "cloud_client = QdrantClient(\n",
        "    url=QDRANT_API_URL,\n",
        "    api_key=QDRANT_API_KEY,\n",
        "    prefer_grpc=True,\n",
        ")\n",
        "\n",
        "# create conditional deletion flag\n",
        "delete_collection = False\n",
        "\n",
        "if delete_collection:\n",
        "    # list of collections to drop\n",
        "    collections_to_reset = [\n",
        "        \"johnwick_baseline\",\n",
        "        \"johnwick_parent_children\",\n",
        "        \"johnwick_semantic\",\n",
        "    ]\n",
        "\n",
        "    for col_name in collections_to_reset:\n",
        "        # guard against missing collections\n",
        "        if cloud_client.collection_exists(col_name):\n",
        "            cloud_client.delete_collection(\n",
        "                collection_name=col_name,\n",
        "                timeout=60,  # seconds\n",
        "            )\n",
        "            print(f\"Deleted collection: {col_name}\")\n",
        "        else:\n",
        "            print(f\"Collection not found (skipped): {col_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KWMPESVcFT_"
      },
      "source": [
        "### Response Object validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bHCFk-PajS6t",
        "outputId": "e77ca077-2d16-41d5-d5dc-fb5036f20e65"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The reviews highlight that the first John Wick film was well-received for its slick action sequences, Keanu Reeves' confident performance, and stylish direction. It has been praised as one of the best action films in recent years, with exciting and meticulously choreographed fight scenes. Many reviewers recommend it especially to action fans, noting its fun, brutal, and engaging nature. Although there are some mixed opinions, the overall reception is very positive.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "People's opinions on John Wick vary based on the reviews in the provided context. \n",
            "\n",
            "The first John Wick movie generally received very positive feedback, with reviewers praising its stylish and smooth action sequences, clear and simple plot, and Keanu Reeves' performance. For example, one reviewer rated it 10/10 and called it \"something special\" and a \"must see for action fans,\" while another gave it an 8/10 for its kinetic and concise style.\n",
            "\n",
            "However, later installments seem to have mixed or negative reactions. For instance, John Wick: Chapter 4 was described as the weakest of the series by one reviewer, who criticized its lengthy runtime and lack of meaningful plot, though this review still gave it a rating of 4/10. Meanwhile, John Wick 3 received a very negative review, with criticism of its plotlessness, excessive violence, and stereotypes.\n",
            "\n",
            "In summary, while the original John Wick film was generally well-liked, subsequent films, especially the third and fourth, received a more mixed to negative reception from some viewers. So, overall, people liked John Wick 1 a lot, but later movies divided opinion.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. Reviews describe it as \"one of the absolute best [action films] in the past decade,\" praising Keanu Reeves' performance, the slick and meticulously choreographed action sequences, and the engaging criminal underworld setting. It was highly recommended for action fans and considered a must-see for those looking for something different and fun. However, some later installments like John Wick 3 received more mixed reviews. Overall, the original John Wick was very well received.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked the movie *John Wick*. Many reviews praise the film for its slick action sequences, Keanu Reeves' performance, and its fresh take on the revenge thriller genre. Reviewers described it as \"the coolest action film,\" \"kinetic, concise, and stylish,\" and \"one of the absolute best in the past decade.\" It is appreciated for its fast-paced, well-choreographed action scenes and engaging, straightforward plot. While there are some mixed opinions, particularly about the sequels, the first *John Wick* movie received predominantly positive reviews and is highly recommended for action fans.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the provided reviews, people generally liked the John Wick series. One review praises the original John Wick movie for its well-choreographed action and emotional setup, recommending it highly. Another review mentions that the first three films have consistent IMDb ratings around 7.4/10 and expresses that John Wick: Chapter 4 is the best in the series. However, there are also some negative opinions, such as one review calling John Wick 4 \"horrible\" and criticizing the plot and fight scenes.\n",
            "\n",
            "Overall, the majority sentiment from the given context suggests that people generally like John Wick, though there are some who do not.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Based on the reviews provided, people generally liked the first **John Wick** movie and the early parts of the series. The original film received praise for its stylish and well-choreographed action sequences, Keanu Reeves' performance, and its fresh take on the revenge thriller genre. For example:\n",
            "\n",
            "- One reviewer gave it a rating of 10, calling it a must-see for action fans, praising the smooth action sequences and the unique criminal underworld the film portrays.\n",
            "- Another review with a 9 rating highlighted it as the coolest action film of the year, emphasizing its fun, violent, and well-crafted action scenes.\n",
            "- An 8 rated review described it as kinetic, concise, and stylish, successfully delivering awesome action and a relatable hero.\n",
            "- Even a 7-rated review appreciated the violent and gripping story with nonstop action and thrilling fight scenes.\n",
            "\n",
            "However, some reviews also showed mixed or less favorable opinions, especially for the later films in the series (John Wick 3 and John Wick 4), which some found overly violent, tiring, or lacking plot depth. There were also a few lower ratings and critiques of the franchise as it progressed.\n",
            "\n",
            "In summary, **the general sentiment toward the first John Wick film and the early franchise entries is quite positive, especially among action movie fans, though later installments received more mixed reactions.**\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval Chain Response\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yes, people generally liked John Wick. The first film received very positive reviews, with ratings around 8 to 10 out of 10, praised for its smooth, stylish, and well-choreographed action sequences, compelling world-building, and Keanu Reeves' confident performance. Reviewers described it as a standout, thrilling action movie with a simple but effective revenge plot.\n",
            "\n",
            "Although some later installments like John Wick 3 had more mixed reviews ‚Äî with some critics feeling the magic had faded and giving lower ratings (such as 5 or even 0) ‚Äî overall the franchise maintained a strong fan base. John Wick 4, for example, received high praise and ratings (around 9/10), with people appreciating the heightened action and consistent quality.\n",
            "\n",
            "In summary, the John Wick series has been well received overall, especially for its action, style, and Keanu Reeves' role.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to response objects\n",
        "responses = {\n",
        "    \"Naive Retrieval Chain Response\":              naive_retrieval_chain_response,\n",
        "    \"BM25 Retrieval Chain Response\":               bm25_retrieval_chain_response,\n",
        "    \"Contextual Compression Chain Response\":       contextual_compression_retrieval_chain_response,\n",
        "    \"Multi-Query Retrieval Chain Response\":        multi_query_retrieval_chain_response,\n",
        "    \"Parent Document Retrieval Chain Response\":    parent_document_retrieval_chain_response,\n",
        "    \"Ensemble Retrieval Chain Response\":           ensemble_retrieval_chain_response,\n",
        "    \"Semantic Retrieval Chain Response\":           semantic_retrieval_chain_response,\n",
        "}\n",
        "\n",
        "for header, resp in responses.items():\n",
        "    display(Markdown(f\"## {header}\\n\"))\n",
        "    print(\"\\n\")\n",
        "    print(resp)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GGRzkNHjPUd"
      },
      "source": [
        "### Retrieval Chain validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vZOd4DL9NS3k",
        "outputId": "860d77fb-83d0-4ec7-a8d3-27cb66d8ae60"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Naive Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## BM25 Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7fa8b4087a50>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Contextual Compression\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7fa89489c690>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10})),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Multi-Query Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser()),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Parent Document Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8b444b910>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7fa928804e90>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7fa8b444b7d0>),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Ensemble Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | EnsembleRetriever(retrievers=[BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7fa8b4087a50>), VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10}), ParentDocumentRetriever(vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8b444b910>, docstore=<langchain.storage.encoder_backed.EncoderBackedStore object at 0x7fa928804e90>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x7fa8b444b7d0>), ContextualCompressionRetriever(base_compressor=CohereRerank(client=<cohere.client_v2.ClientV2 object at 0x7fa89489c690>, top_n=3, model='rerank-english-v3.0', cohere_api_key=SecretStr('**********'), base_url=None, user_agent='langchain:partner'), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10})), MultiQueryRetriever(retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e6523850>, search_kwargs={'k': 10}), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an AI language model assistant. Your task is \\n    to generate 3 different versions of the given user \\n    question to retrieve relevant documents from a vector  database. \\n    By generating multiple perspectives on the user question, \\n    your goal is to help the user overcome some of the limitations \\n    of distance-based similarity search. Provide these alternative \\n    questions separated by newlines. Original question: {question}')\n",
            "             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
            "             | LineListOutputParser())], weights=[0.2, 0.2, 0.2, 0.2, 0.2]),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Semantic Retrieval\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first={\n",
            "  context: RunnableLambda(itemgetter('question'))\n",
            "           | VectorStoreRetriever(tags=['QdrantVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7fa8e645f2d0>, search_kwargs={'k': 10}),\n",
            "  question: RunnableLambda(itemgetter('question'))\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "})] last={\n",
            "  response: ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are a helpful and kind assistant. Use the context provided below to answer the question.\\n\\nIf you do not know the answer, or are unsure, say you don't know.\\n\\nQuery:\\n{question}\\n\\nContext:\\n{context}\\n\"), additional_kwargs={})])\n",
            "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa9288fdc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa928801950>, root_client=<openai.OpenAI object at 0x7fa92903ca10>, root_async_client=<openai.AsyncOpenAI object at 0x7fa928ed7550>, model_name='gpt-4.1-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  context: RunnableLambda(itemgetter('context'))\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Map of titles to chains\n",
        "chains = {\n",
        "    \"Naive Retrieval\":              naive_retrieval_chain,\n",
        "    \"BM25 Retrieval\":               bm25_retrieval_chain,\n",
        "    \"Contextual Compression\":       contextual_compression_retrieval_chain,\n",
        "    \"Multi-Query Retrieval\":        multi_query_retrieval_chain,\n",
        "    \"Parent Document Retrieval\":    parent_document_retrieval_chain,\n",
        "    \"Ensemble Retrieval\":           ensemble_retrieval_chain,\n",
        "    \"Semantic Retrieval\":           semantic_retrieval_chain,\n",
        "}\n",
        "\n",
        "for title, chain in chains.items():\n",
        "    display(Markdown(f\"## {title}\\n\"))\n",
        "    print(chain)\n",
        "    # print(chain.get_graph().draw_ascii())\n",
        "    print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
